{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5Ac5Xnv8e+zszftrm6LVhd0QUJSABEbAWuBzfGVSxDnFMKJSeQ6xxDHFUHKOg7HdmIlroqp5BwXcXBccYxRRKwETmEUHJugIrIFJgYfB0O0wkJIAqHVfe83sau9zc7uPueP6SXDMKudkXamZ3d+n6qpmXn7fbuf7pX6mX777W5zd0REpPAUhR2AiIiEQwlARKRAKQGIiBQoJQARkQKlBCAiUqCKww4gE/PmzfPly5eHHYaIyJSyd+/eDnevSS6fUglg+fLl1NXVhR2GiMiUYmYnU5WrC0hEpEApAYiIFCglABGRAqUEICJSoJQAREQKlBKAiEiBUgIQESlQSgAiInmstWeQB3cf5mh776TPWwlARCSPHe/o4zs/q6ele3DS560EICKSxzp7hwC4qKp00uetBCAikse6+qIAVFcqAYiIFJSO4AigukIJQESkoHT2RZlbUUJxZPJ310oAIiJ5rLN3iIuqyrIy77QSgJndamaHzazezLakmH65mf3SzKJm9uWE8svMbF/Cq8fM7gum3W9mjQnTbpu81RIRmR46+4a4KAv9/5DG8wDMLAI8BNwMNAB7zGynux9KqNYFfAG4I7Gtux8G1ibMpxF4KqHKt9z9wQtaAxGRaayzN8plC2dmZd7pHAGsA+rd/Zi7DwE7gA2JFdy9zd33ALFzzOdG4Ki7p3wwgYiIvFf8CCC8LqDFwOmE7w1BWaY2Ak8klW02s/1mtt3M5qZqZGabzKzOzOra29vPY7EiIlNTbGSUt/tjWbkGANJLAJaizDNZiJmVArcDP0gofhhYSbyLqBn4Zqq27r7N3Wvdvbam5j2PtBQRmbbO9I9dBBbeEUADsDTh+xKgKcPlrAdedffWsQJ3b3X3EXcfBR4h3tUkIiKBd64CztJJ4HQSwB5gtZmtCH7JbwR2ZricT5PU/WNmixK+fhI4kOE8RUSmtWwngAlHAbn7sJltBnYDEWC7ux80s3uD6VvNbCFQB8wCRoOhnmvcvcfMKoiPILonadbfMLO1xLuTTqSYLiJS0DqD20BkqwtowgQA4O67gF1JZVsTPrcQ7xpK1bYfuChF+WcyilREpMCM3QZiXogngUVEJARdfVGKi4xZ5SVZmb8SgIhInursHWJuZSlFRakGY144JQARkTzV0Zu920CAEoCISN7q7IsyL0sngEEJQEQkb3X1DWXtKmBQAhARyVudvdm7DxAoAYiI5KXB2Ai90WEdAYiIFJrOvuxeBQxKACIieamrN7s3ggMlABGRvNTxzm0gdAQgIlJQsn0jOFACEBHJS5292b0RHCgBiIjkpa6+IcqKi6gsjWRtGUoAIiJ5qKN3iHlVZZhl5z5AoAQgIpKXOvuiWT0BDEoAIiJ5qbN3iOosngAGJQARkbzU1Zfd20CAEoCISN5xdzp6o1l7EtiYtBKAmd1qZofNrN7MtqSYfrmZ/dLMomb25aRpJ8zsdTPbZ2Z1CeXVZvacmR0J3ude+OqIiEx9fUMjRIdHwz8HYGYR4CFgPbAG+LSZrUmq1gV8AXhwnNl83N3XunttQtkW4Hl3Xw08H3wXESl4Y9cAVOdBF9A6oN7dj7n7ELAD2JBYwd3b3H0PEMtg2RuAR4PPjwJ3ZNBWRGTa6njnPkCljHR30/3008Ta2iZ9OekkgMXA6YTvDUFZuhx41sz2mtmmhPIF7t4MELzPT9XYzDaZWZ2Z1bW3t2ewWBGRqWnsCGBeZRnRI0do+soWom8dmfTlpJMAUl2F4Bks4wZ3v4Z4F9LnzewjGbTF3be5e62719bU1GTSVERkSmrtGQRgwewyhhoaAChZfPGkLyedBNAALE34vgRoSncB7t4UvLcBTxHvUgJoNbNFAMH75B/fiIhMQS09g0SKjIsqy4g1NAJQsjiTjpf0pJMA9gCrzWyFmZUCG4Gd6czczCrNbObYZ+AW4EAweSdwd/D5buDpTAIXEZmuWnuizJ9ZRqTIiDU2Ujx/PkWlkz8iqHiiCu4+bGabgd1ABNju7gfN7N5g+lYzWwjUAbOAUTO7j/iIoXnAU8G9LIqB77v7T4JZPwA8aWafA04Bd07uqomITE2tPYPMn1UOQKyhgZIlS7KynAkTAIC77wJ2JZVtTfjcQrxrKFkPcNU48+wEbkw7UhGRAtHSPcilNZUAxBobmVF7bVaWoyuBRUTyTGvPIAtnleOxGLGWlqz0/4MSgIhIXhkYGqFncJj5s8qJtbTA6CilWeoCUgIQEckjLcEQ0IWzyok1jo0AUgIQEZn2xq4BWDi7nNjYNQBL1AUkIjLtvXMR2KwyhhobIRKhZOHCrCxLCUBEJI/8ZwIoJ9bQSMmCBVhxWgM2M6YEICKSR1q6o1SURqgqK87qNQCgBCAiklfGhoCaxa8CVgIQESkQrT2DLJhVzmg0ynBbW1ZuAjdGCUBEJI+09AyyYFYZsab4PTezdQ0AKAGIiOQNd6etJ8qC2eVZvQvoGCUAEZE8caY/xtDIaHAR2Ng1ADoCEBGZ9lq6E4aANjZCSQnF81M+LHFSKAGIiOSJxGsAhhoaKLl4EVaUvd20EoCISJ5IvAo41thEaZbuATRGCUBEJE+M3Qhu/szyrF8EBkoAIiJ5o7VnkHlVpRRHBxjp6srqCCBQAhARyRvxZwGXv3MNQLbuAjomrQRgZrea2WEzqzezLSmmX25mvzSzqJl9OaF8qZn9zMzeMLODZvaHCdPuN7NGM9sXvG6bnFUSEZmaWroHWTg7fgIYoDTLRwAT3mLOzCLAQ8DNQAOwx8x2uvuhhGpdwBeAO5KaDwNfcvdXzWwmsNfMnkto+y13f/CC10JEZBpo7RnkqqVzGDp5EICSSy7J6vLSOQJYB9S7+zF3HwJ2ABsSK7h7m7vvAWJJ5c3u/mrw+SzwBpDdlCYiMgUNDY/S2TcUHwF06hRFs2YRmTMnq8tMJwEsBk4nfG/gPHbiZrYcuBp4JaF4s5ntN7PtZjZ3nHabzKzOzOra29szXayIyJTQdvY/HwU5dOIkpZdcgplldZnpJIBUEXgmCzGzKuCHwH3u3hMUPwysBNYCzcA3U7V1923uXuvutTU1NZksVkRkynjXRWCnTlG6bFnWl5lOAmgAliZ8XwI0pbsAMyshvvN/3N1/NFbu7q3uPuLuo8AjxLuaREQKUmtPFIAFMyLEmpoozXL/P6SXAPYAq81shZmVAhuBnenM3OLHL98D3nD3v06atijh6yeBA+mFLCIy/TSeGQBgfl8njI5Sekn2jwAmHAXk7sNmthnYDUSA7e5+0MzuDaZvNbOFQB0wCxg1s/uANcD7gc8Ar5vZvmCWf+ruu4BvmNla4t1JJ4B7JnfVRESmjoYz/cwsK6asJX4b6FwcAaT1pOFgh70rqWxrwucW4l1DyX5B6nMIuPtn0g9TRGR6O31mgCXVFQydOgpkfwgo6EpgEZG80HCmnyVzZ+RsCCgoAYiIhM7dOd01wNK5FfEhoMuWZX0IKCgBiIiErrNviIHYCEurZ8SHgOag+weUAEREQtcQjABaUlWSsyGgoAQgIhK60139ACwZ7MrZEFBQAhARCd3YEcC87vjtbnQEICJSIE6f6WduRQlFTfHbruViCCgoAYiIhO50Vz9LqytyOgQUlABERELXeGaAJXNn5HQIKCgBiIiEanTUaTgTXANw8mTO+v9BCUBEJFTtvVGGRkZZWhUh1tycsxFAoAQgIhKqsSGgy2LdwRBQHQGIiBSEsSGgC892ALkbAgpKACIioRo7ApjdHr8NdK6GgIISgIhIqE6f6admZhkjx48TmTeP4rkpH4+eFUoAIiIhio8AmsHQ0aOUrVyZ02UrAYiIhOj0mX6WzJlBVAlARKRwDI+M0vz2IKsjA4z29lK6Kg8TgJndamaHzazezLakmH65mf3SzKJm9uV02ppZtZk9Z2ZHgvfcdXyJiOSBlp5Bhked5X1tAJStXJXT5U+YAMwsAjwErCf+oPdPm9mapGpdwBeABzNouwV43t1XA88H30VECsbprvgQ0EVnWgAoy8MjgHVAvbsfc/chYAewIbGCu7e5+x4glkHbDcCjwedHgTvOcx1ERKakhjPBENC200RmzyZSXZ3T5aeTABYDpxO+NwRl6ThX2wXu3gwQvM9PNQMz22RmdWZW197enuZiRUTy38nOfiJFRvHpk5SuWpWzm8CNSScBpIrI05z/hbSNV3bf5u617l5bU1OTSVMRkbx2tL2XS6pnEAthBBCklwAagKUJ35cATWnO/1xtW81sEUDw3pbmPEVEpoWj7b38euUoI93dOe//h/QSwB5gtZmtMLNSYCOwM835n6vtTuDu4PPdwNPphy0iMrUNj4xyoqOf9w13AVAawhFA8UQV3H3YzDYDu4EIsN3dD5rZvcH0rWa2EKgDZgGjZnYfsMbde1K1DWb9APCkmX0OOAXcOdkrJyKSrxrODDA0MsqK3mAI6KrcDgGFNBIAgLvvAnYllW1N+NxCvHsnrbZBeSdwYybBiohMF0fbewGY39VMUVUVxfNTjoPJqrQSgIiITK6xBFDZfIrIypU5HwEEuhWEiEgojrb1Ma+qlJETx3N+C4gxSgAiIiE41tHLlVUw0tGR81tAjFECEBEJwdH2PtaOvg3k/hYQY3QOQEQkx7r6hujqG2JVUXwEUOml6gISESkIx4ITwIs6GiiqqqLk4kWhxKEEICKSY2MjgGaePkbZ5ZdhReHsipUARERy7Gh7HzMi4EePUH5F8t31c0cJQEQkx4629VJb0ocPDFB+xRWhxaEEICKSY0fbe7k2Gr+9ffkaJQARkYIQHR7hVFc/q3saoaSEsksvDS0WJQARkRw61dnPqMOCtlOUrV6FlZaGFosSgIhIDh1t7wV3Kk4fC7X/H5QARERyqr6tl4sGe7C3z1B+uRKAiEjBeKP5LNePdADhngAGJQARkZw62NTNNbF2MKPssstDjUUJQEQkR84OxjjR2c+q7kZKly0jUlUZajxKACIiOfJmy1kAqptPUBbyCWBIMwGY2a1mdtjM6s1sS4rpZmbfDqbvN7NrgvLLzGxfwqsneF4wZna/mTUmTLttcldNRCS/HGzspnJogOLW5tBHAEEat4M2swjwEHAz0ADsMbOd7n4oodp6YHXwug54GLjO3Q8DaxPm0wg8ldDuW+7+4GSsiIhIvjvY1MPVsfgtoMM+AQzpHQGsA+rd/Zi7DwE7gA1JdTYAj3ncy8AcM0u+v+mNwFF3P3nBUYuITEEHm3pYNxyMAMqDI4B0EsBi4HTC94agLNM6G4Enkso2B11G281sbqqFm9kmM6szs7r29vY0whURyT9Dw6McaTvLFd0NFC9YQPG8eWGHlFYCSPWoes+kjpmVArcDP0iY/jCwkngXUTPwzVQLd/dt7l7r7rU1NTVphCsikn/eaj1LbMRZcPotZlx9ddjhAOklgAZgacL3JUBThnXWA6+6e+tYgbu3uvuIu48CjxDvahIRmZYONfdQPdBNSXsrM9ZeFXY4QHoJYA+w2sxWBL/kNwI7k+rsBO4KRgNdD3S7e3PC9E+T1P2TdI7gk8CBjKMXEZkiDjX1sPZsvKe8Yu3akKOJm3AUkLsPm9lmYDcQAba7+0EzuzeYvhXYBdwG1AP9wGfH2ptZBfERRPckzfobZraWeFfRiRTTRUSmjYNN3dwy2ISVllK2JryngCWaMAEAuPsu4jv5xLKtCZ8d+Pw4bfuBi1KUfyajSEVEpqjRUedQUw//s/Mk5VdeSVGIt4BOpCuBRUSy7GRXP0MDUS5qPJY3J4BBCUBEJOsONnWzsruRouFY3pwABiUAEZGsO9jUw5Vn4tfAzsiTE8CgBCAiknW/OnWGdf2NlCxeTMn8+WGH8w4lABGRLBoaHmXfqTOsaj+eV7/+QQlARCSrDjZ1M7Oni4qeLiUAEZFCsvfkGa7oCvr/82gEECgBiIhk1Z4TXazrb8DKyym/7NfCDuddlABERLLE3ak7cYarO+qpuOYarKQk7JDeRQlARCRLjnf0MdrZQXVbA5Uf+mDY4byHEoCISJbUnTzD2vZ6ACo+qAQgIlIw6k50se5MPUWzZ+fFE8CSKQGIiGRJ3fEurm2vp/KDH8SK8m93m38RiYhMAx29UaInTjDzbBeVedj9A0oAIiJZUXfiDFe3HwHIyxPAoAQgIpIVe092cW3HEYqXLKF06dKJG4RACUBEJAteequNtZ1HqcrT7h9QAhARmXQt3YMMv3GI8uhA3nb/QJoJwMxuNbPDZlZvZltSTDcz+3Ywfb+ZXZMw7YSZvW5m+8ysLqG82syeM7MjwfvcyVklEZFwvfhW2zv9/xXXXx9yNOObMAGYWQR4CFgPrAE+bWbJTzReD6wOXpuAh5Omf9zd17p7bULZFuB5d18NPB98FxGZ8l443M6HOt6ibM0aiufm72/bdI4A1gH17n7M3YeAHcCGpDobgMc87mVgjpktmmC+G4BHg8+PAndkELeISF6KjYzy+v5jrOo4zsybbgw7nHNKJwEsBk4nfG8IytKt48CzZrbXzDYl1Fng7s0AwXvKx+SY2SYzqzOzuvb29jTCFREJz6snz/C+k69h7sy86aawwzmndBKApSjzDOrc4O7XEO8m+ryZfSSD+HD3be5e6+61NTU1mTQVEcm5F95q54bmAxQvXUbZ6tVhh3NO6SSABiBxEOsSoCndOu4+9t4GPEW8SwmgdaybKHhvyzR4EZF88/L+k6ztqGfWLTdhluq3cf5IJwHsAVab2QozKwU2AjuT6uwE7gpGA10PdLt7s5lVmtlMADOrBG4BDiS0uTv4fDfw9AWui4hIqFp7Bpnz2n8QGR3J++4fgOKJKrj7sJltBnYDEWC7ux80s3uD6VuBXcBtQD3QD3w2aL4AeCrIgsXA9939J8G0B4AnzexzwCngzklbKxGRELx4uJ0PNb8OF81jxlVXhR3OhCZMAADuvov4Tj6xbGvCZwc+n6LdMSDlVnD3TiC/T5GLiGTgxdcb+P22w8z51G/m5d0/k+V/hCIiU0BvdJieX/yCsuEhZt6c/90/oAQgIjIpnjvUwgdO78erZlK5bt3EDfKAEoCIyCTY9R/H+XDz68y++aa8e/j7eJQAREQuUGdvFH7+M8qHo8z9rd8MO5y0KQGIiFygXQdauOnEK7B4CTOuvTbscNKmBCAicoF+8eI+3t95jHl3/lbeX/yVSAlAROQCNL49wPyXfopbEXPumFr3tFQCEBG5AM/86jQ3naojsu46ShYuDDucjCgBiIicJ3fnwDP/xvyBt1m0cerdzEAJQETkPL1yvIsrXvs5w5VVVH3iE2GHkzElABGR8/TPP97Lhxtfo/qTd1BUVhZ2OBlTAhAROQ+Nbw8w58c/osig5nd/N+xwzosSgIjIeXji3w6x/sTLlN50C6VLkh+SODUoAYiIZGgwNkL3k09SMRxl6b2/H3Y4500JQEQkQzv3HOeWN18gtraW8jVrwg7nvCkBiIhkYHTUOfDYD5g32MOlm+8JO5wLogQgIpKBXa81cEPdTxi8ZCWVN9wQdjgXRAlARCRNwyOjvPzQoyzrbWPFF78wpe77k0paCcDMbjWzw2ZWb2ZbUkw3M/t2MH2/mV0TlC81s5+Z2RtmdtDM/jChzf1m1mhm+4LXbZO3WiIik++pl46wfs9Oopf/OrNvuTnscC7YhM8ENrMI8BBwM9AA7DGzne5+KKHaemB18LoOeDh4Hwa+5O6vmtlMYK+ZPZfQ9lvu/uDkrY6ISHYMxkY4+p2/49ejZ7nka1+d8r/+Ib0jgHVAvbsfc/chYAewIanOBuAxj3sZmGNmi9y92d1fBXD3s8AbwNQcMCsiBe0Hu3/Fbxz4KdEPf4KKq9eGHc6kSCcBLAZOJ3xv4L078QnrmNly4GrglYTizUGX0XYzm5tq4Wa2yczqzKyuvb09jXBFRCbX2/1D9D78ECU+ypo/e08v+JSVTgJIdZzjmdQxsyrgh8B97t4TFD8MrATWAs3AN1Mt3N23uXutu9fW1NSkEa6IyOT6+4d+xEeOvkLRb/0OpUuXhh3OpEknATQAiWu8BGhKt46ZlRDf+T/u7j8aq+Dure4+4u6jwCPEu5pERPLKL14/zdU7vsPARfO5fMsXww5nUqWTAPYAq81shZmVAhuBnUl1dgJ3BaOBrge63b3Z4mdJvge84e5/ndjAzBYlfP0kcOC810JEJAsGhkZ47Wtf5+K+Tlb+1QMUVVaGHdKkmnAUkLsPm9lmYDcQAba7+0EzuzeYvhXYBdwG1AP9wGeD5jcAnwFeN7N9Qdmfuvsu4BtmtpZ4V9EJYGpfUici085jW5/iE4deIHr7p5j7oevDDmfSmXtyd37+qq2t9bq6urDDEJEC8NK+40R/739QMaOUDzz3rxRVVIQd0nkzs73uXptcPuERgIhIoWno7OXU//oiVw52s3jrP07pnf+56FYQIiIJBmMjPLP5q1zV/CZlX/oK1eve88N52lACEBEJuDuP/flWPvqrZzl76wZ+7XOfCTukrFICEBEJPP7dH3LdD7fSsfJKPvBXfxF2OFmnBCAiAjy57Smu/O6fc7ZmEdc9tg0rKQk7pKxTAhCRgvfUP+xk9d98jb7qBdT+8/cpvag67JByQqOARKRguTtP/u0T/NrfPUDfnBqu/efHKa+ZF3ZYOaMEICIFKRob4Z++9HWuffYJOhYt59rv/wMzFswPO6ycUgIQkYLT3tHNTzd9kQ8ceonmq2/go9/7NpFpOtb/XHQOQEQKygtPv8D+225n7aGXaP/UXXz8+48U5M4fdAQgIgWiu6ePn/zx/+HKF/6Fnqo5FH3zO3zkv94YdlihUgIQkWktNjzC7u9+n5mPbuX9fV2cWvcJPvI3X2fG3NlhhxY6JQARmZaGR0b5f0/8KwOPbGVl6zFa5i1h5Gv38xu3T/2HuU8WJQARmVYG+gd5cdsOin7wOEs7G3i7YjYdf/BHfPTzd1FUrF1eIm0NEZny3J39L9Zx9LEdLN77IpdE+2iZu4i2P/gjPnTPf6ekvCzsEPOSEoCITEmxoRj7nv13Gp/Zzexf/ZKF3a2sKopw+vJain7nU3z0U+spikTCDjOvKQGIyJQw0DfAmy+9SuPPX2b0V3tZdPJNqmIDrLQiGpZdQeMdd3LtZ3+b9y+sCTvUKUMJQETyysjwCC3HGzi97xBdB98kVn+UGSfrWdjRQLmPsBJom1VD89oPMvuGG7j6U+t537y5YYc9JaWVAMzsVuBviD8T+O/d/YGk6RZMv434M4F/191fPVdbM6sG/glYTvyZwL/t7mcufJVEJF8NDUbpam6nq6GF7qZW+prbGGxqZqS1hUhHGxVdbVR3t1M2OsxsYDZwtqySzvnLOPnx25l99ftZ9bHruWL18pDXZHqYMAGYWQR4CLgZaAD2mNlOdz+UUG09sDp4XQc8DFw3QdstwPPu/oCZbQm+f2XyVk1ExjM6OsroyCgjw8OMDI8wHBuOfx4aZnhoiOHYMMPRGMOxIWLRIUaiMWKDUYYHowxHh+LvAwMMD0YZGRhktL+fkcEBvH8A7++HgX5sYIDigV5KBvooG+ynMtpHRWwQAAPmBC+As6UV9Myspq/mYnqv+gCly5ZRffkqll/7Pi5ftoj4b0yZbOkcAawD6t39GICZ7QA2AIkJYAPwmMefMP+ymc0xs0XEf92P13YD8LGg/aPAC2QpATzz5f9Nxb//WzZmLRfCPewI3iPj3UzCOhjnWJ+ESe+ql1wezM8S5p1Y38bK3AF/p565Y8F38/h8ioL5GU7R6ChFBPXciZwr1hQiwWsiMYswWFJGtKScobJyYuWVRGdXM7BoKWdmzaFozhxK5s6hfH4NMy9ewJzFC1l46VIqZ1dlFI9MjnQSwGLgdML3BuK/8ieqs3iCtgvcvRnA3ZvNLOVt+MxsE7AJYNmyZWmE+16l82voXbj0vNpKtuXhL7tMQ0r8dXrOX6qW8uO7y+2debglTEsof9f3cV9F//m5qAgrCr5HiqCoCKwIi0Ti5ZEirCiClZRgxREsUkxRSTFWXEykpJii0lIipaVEykooLiujpLyM4vJyyirLKausoKyinBmzqphRVUGphltOKekkgFT/opN/PoxXJ5225+Tu24BtALW1tef1k/GWP74HuOd8moqITFvp3A20AUj8+bwEaEqzzrnatgbdRATvbemHLSIiFyqdBLAHWG1mK8ysFNgI7EyqsxO4y+KuB7qD7p1ztd0J3B18vht4+gLXRUREMjBhF5C7D5vZZmA38fNA2939oJndG0zfCuwiPgS0nvgw0M+eq20w6weAJ83sc8Ap4M5JXTMRETkn8zwciTGe2tpar6urCzsMEZEpxcz2unttcrmeCCYiUqCUAERECpQSgIhIgVICEBEpUFPqJLCZtQMnz7P5PKBjEsOZLIorM4orM4orM/kaF1xYbJe4+3vukz2lEsCFMLO6VGfBw6a4MqO4MqO4MpOvcUF2YlMXkIhIgVICEBEpUIWUALaFHcA4FFdmFFdmFFdm8jUuyEJsBXMOQERE3q2QjgBERCSBEoCISIGaVgnAzO40s4NmNmpmtUnT/sTM6s3ssJn9xjjtq83sOTM7ErzPzUKM/2Rm+4LXCTPbN069E2b2elAv63fAM7P7zawxIbbbxql3a7AN64NnOWc7rr8yszfNbL+ZPWVmc8apl5PtNdH6B7dE/3Ywfb+ZXZOtWBKWudTMfmZmbwT//v8wRZ2PmVl3wt/3z7IdV7Dcc/5dQtpelyVsh31m1mNm9yXVycn2MrPtZtZmZgcSytLaD03K/0V3nzYv4ArgMuLPF65NKF8DvAaUASuAo0AkRftvAFuCz1uAv8xyvN8E/mycaSeAeTncdvcDX56gTiTYdpcCpcE2XZPluG4BioPPfzne3yQX2yud9Sd+W/QfE38a3vXAKzn42y0Crgk+zwTeShHXx4BncvXvKeNi2qYAAAOiSURBVN2/SxjbK8XftIX4hVI5317AR4BrgAMJZRPuhybr/+K0OgJw9zfc/XCKSRuAHe4edffjxJ9bsG6ceo8Gnx8F7shOpPFfPsBvA09kaxlZsA6od/dj7j4E7CC+zbLG3Z919+Hg68vEnyoXlnTWfwPwmMe9DMwZe/Jdtrh7s7u/Gnw+C7xB/HncU0HOt1eSG4Gj7n6+dxi4IO7+c6ArqTid/dCk/F+cVgngHMZ7aH2ydz2oHkj5oPpJ8mGg1d2PjDPdgWfNbK+ZbcpiHIk2B4fh28c57Ex3O2bL7xH/tZhKLrZXOusf6jYys+XA1cArKSZ/0MxeM7Mfm9mVOQppor9L2P+mNjL+j7Awthektx+alO2WzkPh84qZ/RRYmGLSV919vMdKXvDD6TORZoyf5ty//m9w9yYzmw88Z2ZvBr8WshIX8DDwF8S3y18Q7576veRZpGh7wdsxne1lZl8FhoHHx5nNpG+vVKGmKEte/5z+W3vXgs2qgB8C97l7T9LkV4l3c/QG53f+BVidg7Am+ruEub1KgduBP0kxOaztla5J2W5TLgG4+03n0SydB9tD8KB6d2+2C3hQ/UQxmlkx8JvAteeYR1Pw3mZmTxE/5LugHVq6287MHgGeSTEp3e04qXGZ2d3AfwNu9KADNMU8Jn17pZDO+mdlG03EzEqI7/wfd/cfJU9PTAjuvsvMvmtm89w9qzc+S+PvEsr2CqwHXnX31uQJYW2vQDr7oUnZboXSBbQT2GhmZWa2gngm/49x6uXiQfU3AW+6e0OqiWZWaWYzxz4TPxF6IFXdyZLU7/rJcZa3B1htZiuCX08biW+zbMZ1K/AV4HZ37x+nTq62VzrrvxO4Kxjdcj3QPXY4ny3B+aTvAW+4+1+PU2dhUA8zW0f8/35nluNK5++S8+2VYNyj8DC2V4J09kOT838x22e5c/kivuNqAKJAK7A7YdpXiZ81PwysTyj/e4IRQ8BFwPPAkeC9Oktx/iNwb1LZxcCu4POlxM/qvwYcJN4Vku1t93+B14H9wT+kRclxBd9vIz7K5GiO4qon3te5L3htDXN7pVp/4N6xvyfxQ/OHgumvkzAaLYsx/Rfih//7E7bTbUlxbQ62zWvET6Z/KAdxpfy7hL29guVWEN+hz04oy/n2Ip6AmoFYsO/63Hj7oWz8X9StIEREClShdAGJiEgSJQARkQKlBCAiUqCUAERECpQSgIhIgVICEBEpUEoAIiIF6v8DPE+OyXWwCYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FUNCIONES DE ACTIVACIÓN PARA REDES NEURONALES MULTICAPA\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit,softmax\n",
    "\n",
    "class function(object):\n",
    "    def __init__(self,funcion,derivative=None,rand_init=(0,1)):\n",
    "        self.F=funcion\n",
    "        self.D=derivative\n",
    "        self.Rand_init=rand_init\n",
    "\n",
    "lineal=function(funcion=lambda x:x,\n",
    "                derivative=lambda x:1,\n",
    "                rand_init=(-1,1))\n",
    "\n",
    "sigm=function(funcion=lambda x: expit(x),\n",
    "              derivative=lambda x: expit(x)*(1-expit(x)),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "tanh=function(funcion=lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)),\n",
    "              derivative=lambda x:1-((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))**2,\n",
    "              rand_init=(-1,1))\n",
    "\n",
    "tanh1=function(funcion=lambda x:np.tanh(x),\n",
    "               derivative=lambda x:1-np.tanh(x)**2,\n",
    "               rand_init=(-1,1))\n",
    "\n",
    "relu=function(funcion=lambda x: np.maximum(0, x),\n",
    "              derivative=lambda x: np.where(x<=0,0,1),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "softmaxf=function(funcion=lambda x: softmax(x),\n",
    "                  derivative=lambda x:softmax(x)*(1-softmax(x)),\n",
    "                  rand_init=(0,1))\n",
    "\n",
    "\n",
    "# funciones de coste\n",
    "mse=function(funcion=lambda Yp, Yr: np.mean((Yp - Yr) ** 2) ,\n",
    "                 derivative=lambda Yp, Yr: (Yp - Yr))\n",
    "\n",
    "cross_entropy=function(funcion=lambda yscore,yreal:-np.sum(yreal*np.log(yscore))/yscore.shape[0],\n",
    "                       derivative=lambda yscore,yreal:yscore-yreal)\n",
    "\n",
    "Funciones={\"relu\":relu,\n",
    "           \"sigm\":sigm,\n",
    "           \"relu\":relu,\n",
    "           \"tanh\":tanh,\n",
    "           \"tanh1\":tanh1,\n",
    "           \"lineal\":lineal,\n",
    "           \"softmax\":softmaxf}\n",
    "\n",
    "Loss={\"mse\":mse,\n",
    "      \"cross_entropy\":cross_entropy}\n",
    "\n",
    "_x = np.linspace(-10, 10, 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(_x, softmaxf.F(_x),\"tab:blue\")\n",
    "plt.plot(_x, softmaxf.D(_x),\"tab:red\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "Min_Max = preprocessing.MinMaxScaler()\n",
    "Ordinal =preprocessing.OrdinalEncoder()\n",
    "\n",
    "\n",
    "def one_hot_cols(df,cols_to_one):\n",
    "    one_hot=pd.get_dummies(df,cols_to_one,columns=cols_to_one)\n",
    "    return one_hot\n",
    "\n",
    "def fit_cols(df, cols_to_fit,fit_function ):\n",
    "    for col in cols_to_fit:\n",
    "        df[col] = pd.DataFrame(fit_function.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "def split_Dataset(mypandas, cols_for_Y,size=0.2,state=1):\n",
    "    \n",
    "    X =  mypandas.drop(cols_for_Y, axis=1)\n",
    "    Y = mypandas[cols_for_Y]\n",
    "    X.head()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size, random_state=state)\n",
    "    return X_train.to_numpy(), X_test.to_numpy(), Y_train.to_numpy(), Y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50104, 15)\n",
      "(50104, 2)\n",
      "(12526, 15)\n",
      "(12526, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.15639720e-01, 1.35106159e-01, 4.94386136e-01, ...,\n",
       "        8.47544471e-06, 3.33039836e-07, 2.92081783e-01],\n",
       "       [9.03000208e-01, 1.29515823e-02, 9.35196485e-01, ...,\n",
       "        1.64693301e-05, 6.32775689e-07, 2.16540631e-01],\n",
       "       [5.64642578e-01, 1.42450654e-01, 5.63705150e-01, ...,\n",
       "        5.48977669e-05, 2.13145495e-06, 4.14876165e-01],\n",
       "       ...,\n",
       "       [1.94350860e-01, 7.97292899e-02, 4.89431291e-01, ...,\n",
       "        4.76358517e-05, 1.86502308e-06, 4.87016365e-01],\n",
       "       [5.26960354e-01, 1.36802883e-01, 5.05491823e-01, ...,\n",
       "        5.58608856e-06, 2.33127885e-07, 3.20449726e-01],\n",
       "       [9.97956218e-01, 9.99693680e-01, 2.29716866e-01, ...,\n",
       "        1.49861272e-05, 5.99471706e-07, 2.24662906e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50104, 15)\n",
      "(50104, 2)\n",
      "(12526, 15)\n",
      "(12526, 2)\n"
     ]
    }
   ],
   "source": [
    "#Hacer aquí la normalizacion de los datos\n",
    "import csv\n",
    "data = pd.read_csv('datasets/smoke_detection_iot.csv', encoding='utf-8' )\n",
    "data=one_hot_cols(data,['Fire Alarm'])\n",
    "dataset= fit_cols(data,data.columns,Min_Max)\n",
    "Xtrain,X_test , Ytrain, Y_test = split_Dataset(data,['Fire Alarm_0','Fire Alarm_1'])\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "display(Xtrain)\n",
    "#Xtrain=np.array(Xtrain)\n",
    "#Ytrain=np.array(Ytrain)\n",
    "#with open('datasets/iris.csv') as csvfile:\n",
    "#    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "#    for row in readCSV:\n",
    "#        row=row[0].split(\",\")\n",
    "#        X.append([float(row[0])/10,float(row[1])/10,float(row[2])/10,float(row[3])/10])\n",
    "#\n",
    "#        if row[4]=='\"Setosa\"':\n",
    "#            Y.append([1,0,0])\n",
    "#        if row[4]=='\"Versicolor\"':\n",
    "#            Y.append([0,1,0])\n",
    "#        if row[4]=='\"Virginica\"':\n",
    "#            Y.append([0,0,1])\n",
    "#\n",
    "#\n",
    "#Xtrain=np.array(X)\n",
    "#Ytrain=np.array(Y)\n",
    "#Xtrain=Xtrain[1:-1]\n",
    "#Ytrain=Ytrain[1:-1]\n",
    "#print(np.shape(Xtrain))\n",
    "#print(Xtrain)\n",
    "#print(Xtrain.shape())\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASE DE LA CAPA DE LA RED\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class neural_layer(object):\n",
    "    def __init__(self, n_conn, n_neur, activation=\"relu\"):\n",
    "        self.act = Funciones[activation]\n",
    "        self.activation=activation\n",
    "        self.random=self.act.Rand_init  \n",
    "        self.shape=(n_conn,n_neur)\n",
    "        self.Initialize()\n",
    "        \n",
    "    def show(self,Full=False):\n",
    "        print(f\"Pesos shape:{np.shape(self.W)} bias shape:{np.shape(self.b)} Activation:{self.activation}\")\n",
    "        print(f\"Activation:{self.activation}, Random:{self.random}\")\n",
    "        print(\"______________________\")\n",
    "        if Full:\n",
    "            print(f\"Pesos:\")\n",
    "            print(self.W)\n",
    "            print(\"#####\")\n",
    "            print(f\"Bias:\")\n",
    "            print(self.b)\n",
    "            \n",
    "    def Initialize(self):\n",
    "        #inicializa los pesos iniciales con aleatorios\n",
    "        self.b = np.random.uniform(*self.random,(1, self.shape[1]))      \n",
    "        self.W = np.random.uniform(*self.random,self.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "#CLASE RED NEURONAL MULTICAPA        \n",
    "class Neural_Net(object):\n",
    "    def __init__(self,Input,loss):\n",
    "        self.loss = Loss[loss]\n",
    "        self.Funcion_Loss=loss\n",
    "        self.Input=Input\n",
    "        self.NN=None;\n",
    "              \n",
    "    def Add_Layer(self,Num_neurons, function):\n",
    "        if self.NN is None:\n",
    "            self.NN=[]\n",
    "            self.NN.append(neural_layer(self.Input,Num_neurons,function))\n",
    "        else:\n",
    "            _,L_input=np.shape(self.NN[-1].W)\n",
    "            self.NN.append(neural_layer(L_input,Num_neurons,function))\n",
    "            \n",
    "    def Show_Model(self, Full=False):\n",
    "        print(f\"Input shape:{self.Input}, Loss: {self.Funcion_Loss}\")\n",
    "        for i,L in enumerate(self.NN):\n",
    "            print(F\"Layer_{i}:\")\n",
    "            L.show(Full)\n",
    "            \n",
    "            \n",
    "    # fucnción de predicción (fordware pass)    \n",
    "    def Predict(self,X):  \n",
    "      #sólo podemos pasar Numpy  \n",
    "      sx=np.shape(X)\n",
    "      X=X.reshape(1,sx[0])\n",
    "      if self.NN is None:\n",
    "          print(\"error in Predict Method ( not NEURAL network available)\")\n",
    "          return 0\n",
    "        \n",
    "      out = [(None, X)] #primer data necesario\n",
    "      # Forward pass\n",
    "      for l, layer in enumerate(self.NN):\n",
    "          z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "          a = self.NN[l].act.F(z)\n",
    "          out.append((z, a))\n",
    "      return out[-1][1]\n",
    "    \n",
    "    \n",
    "    # función retropropagación del error\n",
    "    def _backward_pass(self, X, Y,lr=0.01):\n",
    "      sx=np.shape(X)\n",
    "      sy=np.shape(Y)   \n",
    "      X=X.reshape(1,sx[0])\n",
    "      Y=Y.reshape(1,sy[0])\n",
    "\n",
    "      # Forward pass\n",
    "      out = [(None, X)] #primer data necesario\n",
    "      for l, layer in enumerate(self.NN):\n",
    "            z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "            a = self.NN[l].act.F(z)\n",
    "            out.append((z, a))\n",
    "\n",
    "      # Backward pass \n",
    "      deltas = []\n",
    "      for l in reversed(range(0, len(self.NN))):\n",
    "        z = out[l+1][0]\n",
    "        a = out[l+1][1]\n",
    "        if l == len(self.NN) - 1:\n",
    "            deltas.insert(0, self.loss.D(a, Y) * self.NN[l].act.D(a)) # La última capa\n",
    "        else:\n",
    "            deltas.insert(0, deltas[0] @ _W.T * self.NN[l-1].act.D(a))\n",
    "        _W = self.NN[l].W #los pesos en la capa superior\n",
    " \n",
    "        # Gradient descent. actualizamos pesos \n",
    "        self.NN[l].b = self.NN[l].b - (deltas[0]* lr)\n",
    "        self.NN[l].W = self.NN[l].W - (lr * (out[l][1].T @ deltas[0]))\n",
    "      return out[-1][1]\n",
    "\n",
    "    # función de entrenamiento de la red\n",
    "    def Train(self,X,Y,lr=0.01,epoch=10,batch_size=1):\n",
    "        H_loss = []\n",
    "        H_acc=[]\n",
    "        \n",
    "        # inicializamos las capas neuronales a valores ramdom del rango de la función\n",
    "        for Layer in self.NN:\n",
    "            Layer.Initialize()\n",
    "            \n",
    "        for i in range(epoch):\n",
    "            account=0\n",
    "            epoch_Loss=0\n",
    "            epoch_Acc=0\n",
    "            # Entrenemos a la red! con el dataset de validación\n",
    "            for j in range(len(X)):\n",
    "                pY = self._backward_pass(X[j,:], Y[j,:],lr)#fila, fila, learning rate\n",
    "                epoch_Loss+=self.loss.F(pY[0],Y[j,:])\n",
    "                if (Y[j,:]==np.round(pY)).all():#condicion de acertar\n",
    "                    epoch_Acc+=1\n",
    "            H_acc.append(epoch_Acc/len(Y)*100)    \n",
    "            H_loss.append(epoch_Loss/len(Y))#media del error\n",
    "            \n",
    "            #imprimimos por pantalla resultados\n",
    "            print(\"Epoch={}, Accurary={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "            clear_output(wait=True)\n",
    "        print(\"Epoch={}, Accuracy={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "        return H_loss,H_acc\n",
    "\n",
    "    \n",
    "# VISUALIZACIÓN Y TEST\n",
    "def Show_Loss_Acc(H_loss,H_acc):\n",
    "    plt.plot(range(len(H_loss)), H_loss,\"tab:blue\")\n",
    "    plt.ylabel(\"loss function \")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(H_acc)), H_acc, \"tab:red\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "       \n",
    "def print_predict(neural_net,X,Y):\n",
    "    for i in range(len(X)):\n",
    "        sal_float=neural_net.Predict(X[i])\n",
    "        sal=np.round(sal_float)\n",
    "        \n",
    "        if (Y[i]==np.round(sal)).all():\n",
    "            print(\"Input:{}-- Real:{} predict: {} predict_float:{}\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "        else:\n",
    "            print(\"\\x1b[31m Input:{}-- Real:{} predict: {} predict_float:{}\\x1b[0m\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIMOS LOS MODELOs\n",
    "def Model1():\n",
    "    red=Neural_Net(Input=15,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(30,\"relu\")\n",
    "    red.Add_Layer(2,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model2():\n",
    "    red=Neural_Net(Input=15,loss=\"mse\")\n",
    "    red.Add_Layer(8,\"tanh\")\n",
    "    red.Add_Layer(2,\"sigm\")\n",
    "    return red\n",
    "\n",
    "def Model3(): \n",
    "    red=Neural_Net(Input=15,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(16,\"sigm\")\n",
    "    red.Add_Layer(24,\"tanh\")\n",
    "    red.Add_Layer(8,\"relu\")\n",
    "    red.Add_Layer(2,\"softmax\")\n",
    "    return red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:15, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(15, 30) bias shape:(1, 30) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Layer_1:\n",
      "Pesos shape:(30, 2) bias shape:(1, 2) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Input shape:15, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(15, 30) bias shape:(1, 30) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.13840245 0.14604841 0.0191634  0.3251711  0.35586796 0.53524324\n",
      "  0.43055536 0.00972566 0.71432088 0.39025283 0.66485558 0.22506921\n",
      "  0.5688106  0.36132356 0.13528715 0.14006433 0.71229329 0.30390362\n",
      "  0.59995431 0.25951348 0.70613056 0.48479336 0.33480437 0.72319871\n",
      "  0.99214541 0.57330288 0.17553814 0.08301878 0.07263562 0.59701727]\n",
      " [0.2259901  0.71391781 0.90864136 0.40563381 0.55737925 0.96841509\n",
      "  0.08568694 0.7796279  0.61415888 0.08951818 0.45459969 0.59900686\n",
      "  0.07067244 0.73258214 0.716879   0.84579323 0.93313609 0.49764202\n",
      "  0.0682509  0.5712675  0.5872783  0.60460879 0.9458547  0.92337036\n",
      "  0.06285772 0.40914069 0.50582406 0.61618645 0.48301192 0.3040733 ]\n",
      " [0.17995637 0.15851182 0.83829109 0.65491649 0.57147243 0.99386621\n",
      "  0.38478917 0.65819632 0.47560339 0.35072881 0.8565594  0.07573018\n",
      "  0.62327717 0.2851525  0.81484895 0.77085641 0.18661211 0.9873799\n",
      "  0.33861708 0.04476846 0.57027039 0.89606758 0.05613794 0.92924022\n",
      "  0.59374431 0.8576179  0.74411606 0.12045083 0.90143564 0.00224749]\n",
      " [0.91076549 0.84078026 0.85231124 0.09459306 0.1440258  0.99412409\n",
      "  0.53879094 0.11012709 0.11318116 0.05221214 0.07935057 0.67047896\n",
      "  0.42268772 0.26738242 0.85841008 0.38939864 0.59174697 0.91221579\n",
      "  0.48674235 0.60440368 0.04357773 0.65486227 0.0864102  0.13277063\n",
      "  0.89576467 0.40943935 0.98480984 0.51046958 0.48018235 0.59330325]\n",
      " [0.9706104  0.71568923 0.07728385 0.50999137 0.56114271 0.01034246\n",
      "  0.38169691 0.31488432 0.45857763 0.22529069 0.56910332 0.95884155\n",
      "  0.60632118 0.35263779 0.58377284 0.98623824 0.49502408 0.045353\n",
      "  0.3160556  0.16170748 0.68666907 0.91995736 0.88046206 0.30633426\n",
      "  0.82567165 0.25213793 0.55267617 0.97909325 0.77832602 0.57532829]\n",
      " [0.93954719 0.055013   0.18999355 0.28635522 0.11522117 0.88142511\n",
      "  0.45496073 0.58525634 0.81129814 0.77026515 0.88735714 0.49717794\n",
      "  0.01105529 0.25216053 0.23520671 0.72657435 0.05653023 0.99017026\n",
      "  0.46087648 0.82405598 0.97670613 0.90615418 0.44109177 0.15175361\n",
      "  0.75738341 0.80346814 0.63603594 0.32054251 0.16697084 0.70686055]\n",
      " [0.45368432 0.76325568 0.40934383 0.92560771 0.33378716 0.63750787\n",
      "  0.30529759 0.6653103  0.62147713 0.52116849 0.46512532 0.42721929\n",
      "  0.94569003 0.8567811  0.59074856 0.24811839 0.97086479 0.15759308\n",
      "  0.85824157 0.04958241 0.23937862 0.38674835 0.9484081  0.80568284\n",
      "  0.72352597 0.03661178 0.70801401 0.49450104 0.32480609 0.09910162]\n",
      " [0.35696508 0.110923   0.00940458 0.31497119 0.49848775 0.38893907\n",
      "  0.12607486 0.87918057 0.06248899 0.10160322 0.67263526 0.83047464\n",
      "  0.84123607 0.07438001 0.88972949 0.13962937 0.03159019 0.74143793\n",
      "  0.09026522 0.83153782 0.07495149 0.08337029 0.32114081 0.10298762\n",
      "  0.29663571 0.57753035 0.63046402 0.28430723 0.17293476 0.19516625]\n",
      " [0.29070736 0.21794447 0.17952133 0.65645737 0.10009612 0.91287951\n",
      "  0.1305154  0.14174646 0.12673446 0.65180923 0.39061347 0.13154724\n",
      "  0.35248017 0.82242873 0.35237974 0.26332085 0.5405201  0.82346176\n",
      "  0.36175658 0.65251088 0.18419468 0.06846184 0.81765195 0.44286395\n",
      "  0.69218834 0.33234779 0.19033762 0.42239892 0.03111052 0.83357554]\n",
      " [0.67169925 0.34565512 0.14435977 0.67060761 0.84108823 0.48304124\n",
      "  0.49217104 0.15182946 0.70433761 0.05844186 0.00274538 0.21013708\n",
      "  0.44751454 0.04527827 0.45825341 0.60817358 0.90212935 0.13165848\n",
      "  0.75721448 0.25440301 0.58814919 0.50110063 0.14273534 0.75495221\n",
      "  0.24767883 0.40972494 0.3503071  0.81991111 0.91182364 0.72830822]\n",
      " [0.54664684 0.16644725 0.26871031 0.69974359 0.899399   0.87242373\n",
      "  0.26675199 0.08577455 0.00324997 0.67398889 0.08150412 0.81494594\n",
      "  0.58449556 0.61570254 0.96841281 0.14395219 0.88636451 0.54489436\n",
      "  0.03840819 0.9271606  0.65140058 0.54303324 0.94140121 0.11308428\n",
      "  0.47389066 0.54949413 0.25645876 0.35302838 0.69039378 0.86553815]\n",
      " [0.03114898 0.21153849 0.95069301 0.99316302 0.57160278 0.53586891\n",
      "  0.68702492 0.36699283 0.77248513 0.66233074 0.90893403 0.032931\n",
      "  0.65330502 0.74954927 0.45840334 0.62094553 0.7002615  0.0569378\n",
      "  0.08494681 0.49524748 0.28385952 0.19246401 0.12204246 0.3617224\n",
      "  0.22019478 0.49542302 0.87879901 0.1184502  0.34013618 0.19646488]\n",
      " [0.66825118 0.1484624  0.21893131 0.87435453 0.98393248 0.9489612\n",
      "  0.33430932 0.40077114 0.64295315 0.53801976 0.99624654 0.24317322\n",
      "  0.68407339 0.48495048 0.17445155 0.64058539 0.52076927 0.14662577\n",
      "  0.53269954 0.47822074 0.79850016 0.15063479 0.83869987 0.17811773\n",
      "  0.51161236 0.2389857  0.02716952 0.63128097 0.70019536 0.84743808]\n",
      " [0.92868235 0.89334391 0.7218199  0.16358285 0.52093033 0.89396296\n",
      "  0.65902881 0.46834456 0.31611471 0.97436801 0.52195958 0.63772198\n",
      "  0.1027892  0.55475202 0.55736765 0.57823964 0.97261016 0.5257297\n",
      "  0.67570777 0.86746489 0.48709559 0.5446401  0.61039239 0.51664236\n",
      "  0.9527823  0.46093377 0.3744888  0.88518482 0.02479878 0.20468709]\n",
      " [0.83298677 0.96888251 0.64646377 0.66641595 0.80509437 0.59565764\n",
      "  0.1651008  0.92614156 0.91293734 0.32724167 0.81548575 0.64652644\n",
      "  0.36015804 0.27440293 0.75390966 0.95961089 0.18017531 0.18072568\n",
      "  0.88107841 0.06141679 0.59987694 0.02393738 0.40956134 0.63591404\n",
      "  0.59672067 0.29422746 0.2368782  0.54102826 0.11966657 0.64428747]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.7198885  0.43160401 0.76548823 0.76939766 0.64312214 0.11738304\n",
      "  0.96773475 0.51841811 0.63992104 0.46328824 0.04420395 0.10168095\n",
      "  0.90053316 0.66353806 0.36952942 0.69700196 0.90593957 0.88786839\n",
      "  0.62278329 0.22233063 0.09852839 0.29519283 0.2499351  0.2118365\n",
      "  0.32659197 0.08978744 0.72422544 0.06358517 0.47838417 0.24022797]]\n",
      "Layer_1:\n",
      "Pesos shape:(30, 2) bias shape:(1, 2) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.58843591 0.09205625]\n",
      " [0.21909102 0.71671556]\n",
      " [0.40121026 0.11876197]\n",
      " [0.81496487 0.38648701]\n",
      " [0.58377218 0.27640761]\n",
      " [0.92896156 0.52264216]\n",
      " [0.50137234 0.62013732]\n",
      " [0.42209057 0.25647008]\n",
      " [0.31136564 0.20361887]\n",
      " [0.13027582 0.24119695]\n",
      " [0.97950024 0.55022586]\n",
      " [0.25398555 0.26189082]\n",
      " [0.98554828 0.75051847]\n",
      " [0.53475855 0.83734681]\n",
      " [0.45301836 0.35662547]\n",
      " [0.00188929 0.82172538]\n",
      " [0.99707696 0.03117324]\n",
      " [0.93567778 0.13645508]\n",
      " [0.99456245 0.7964023 ]\n",
      " [0.23025222 0.73115478]\n",
      " [0.53009892 0.87276653]\n",
      " [0.77908227 0.45768513]\n",
      " [0.05244328 0.72347461]\n",
      " [0.58391878 0.94997415]\n",
      " [0.75175103 0.58648554]\n",
      " [0.21452333 0.99205534]\n",
      " [0.34239282 0.821043  ]\n",
      " [0.59343605 0.09702265]\n",
      " [0.60170511 0.66146785]\n",
      " [0.50264548 0.48656284]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.70098095 0.66512928]]\n"
     ]
    }
   ],
   "source": [
    "cnn=Model1()\n",
    "cnn.Show_Model()\n",
    "cnn.Show_Model(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=97, Accurary=93.118 Loss=nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)\n",
    "\n",
    "\n",
    "loss,accuracy=cnn.Train(Xtrain,Ytrain,0.2,300)\n",
    "Show_Loss_Acc(loss,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predict(cnn,Xtrain,Ytrain)\n",
    "print(\"::::::::::::::::::::::::::::\")\n",
    "\n",
    "\n",
    "np.round(cnn.Predict(np.array([0.51,0.35,0.14,0.02])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
