{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FUNCIONES DE ACTIVACIÓN PARA REDES NEURONALES MULTICAPA\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit,softmax\n",
    "\n",
    "class function(object):\n",
    "    def __init__(self,funcion,derivative=None,rand_init=(0,1)):\n",
    "        self.F=funcion\n",
    "        self.D=derivative\n",
    "        self.Rand_init=rand_init\n",
    "\n",
    "lineal=function(funcion=lambda x:x,\n",
    "                derivative=lambda x:1,\n",
    "                rand_init=(-1,1))\n",
    "\n",
    "sigm=function(funcion=lambda x: expit(x),\n",
    "              derivative=lambda x: expit(x)*(1-expit(x)),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "tanh=function(funcion=lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)),\n",
    "              derivative=lambda x:1-((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))**2,\n",
    "              rand_init=(-1,1))\n",
    "\n",
    "tanh1=function(funcion=lambda x:np.tanh(x),\n",
    "               derivative=lambda x:1-np.tanh(x)**2,\n",
    "               rand_init=(-1,1))\n",
    "\n",
    "relu=function(funcion=lambda x: np.maximum(0, x),\n",
    "              derivative=lambda x: np.where(x<=0,0,1),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "softmaxf=function(funcion=lambda x: softmax(x),\n",
    "                  derivative=lambda x:softmax(x)*(1-softmax(x)),\n",
    "                  rand_init=(0,1))\n",
    "\n",
    "\n",
    "# funciones de coste\n",
    "mse=function(funcion=lambda Yp, Yr: np.mean((Yp - Yr) ** 2) ,\n",
    "                 derivative=lambda Yp, Yr: (Yp - Yr))\n",
    "\n",
    "cross_entropy=function(funcion=lambda yscore,yreal:-np.sum(yreal*np.log(yscore))/yscore.shape[0],\n",
    "                       derivative=lambda yscore,yreal:yscore-yreal)\n",
    "\n",
    "Funciones={\"relu\":relu,\n",
    "           \"sigm\":sigm,\n",
    "           \"relu\":relu,\n",
    "           \"tanh\":tanh,\n",
    "           \"tanh1\":tanh1,\n",
    "           \"lineal\":lineal,\n",
    "           \"softmax\":softmaxf}\n",
    "\n",
    "Loss={\"mse\":mse,\n",
    "      \"cross_entropy\":cross_entropy}\n",
    "\n",
    "_x = np.linspace(-10, 10, 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(_x, softmaxf.F(_x),\"tab:blue\")\n",
    "plt.plot(_x, softmaxf.D(_x),\"tab:red\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "Min_Max = preprocessing.MinMaxScaler()\n",
    "Ordinal =preprocessing.OrdinalEncoder()\n",
    "\n",
    "\n",
    "def one_hot_cols(df,cols_to_one):\n",
    "    one_hot=pd.get_dummies(df,cols_to_one,columns=cols_to_one)\n",
    "    return one_hot\n",
    "\n",
    "def fit_cols(df, cols_to_fit,fit_function ):\n",
    "    for col in cols_to_fit:\n",
    "        df[col] = pd.DataFrame(fit_function.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "def split_Dataset(mypandas, cols_for_Y,size=0.2,state=1):\n",
    "    \n",
    "    X =  mypandas.drop(cols_for_Y, axis=1)\n",
    "    Y = mypandas[cols_for_Y]\n",
    "    X.head()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size, random_state=state)\n",
    "    return X_train.to_numpy(), X_test.to_numpy(), Y_train.to_numpy(), Y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer aquí la normalizacion de los datos\n",
    "import csv\n",
    "data = pd.read_csv('datasets/smoke_detection_iot.csv', encoding='utf-8' )\n",
    "data=one_hot_cols(data,['Fire Alarm'])\n",
    "data\n",
    "dataset= fit_cols(data,data.columns,Min_Max)\n",
    "Xtrain, X_test, Ytrain, Y_test = split_Dataset(data,['Fire Alarm_0','Fire Alarm_1'])\n",
    "Xtrain=fit_cols(dataset,dataset.columns,Min_Max)\n",
    "Xtrain=Xtrain.drop(['Fire Alarm_0','Fire Alarm_1'],axis=1)\n",
    "Xtrain=np.array(Xtrain)\n",
    "Ytrain=np.array(Ytrain)\n",
    "#with open('datasets/iris.csv') as csvfile:\n",
    "#    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "#    for row in readCSV:\n",
    "#        row=row[0].split(\",\")\n",
    "#        X.append([float(row[0])/10,float(row[1])/10,float(row[2])/10,float(row[3])/10])\n",
    "#\n",
    "#        if row[4]=='\"Setosa\"':\n",
    "#            Y.append([1,0,0])\n",
    "#        if row[4]=='\"Versicolor\"':\n",
    "#            Y.append([0,1,0])\n",
    "#        if row[4]=='\"Virginica\"':\n",
    "#            Y.append([0,0,1])\n",
    "#\n",
    "#\n",
    "#Xtrain=np.array(X)\n",
    "#Ytrain=np.array(Y)\n",
    "#Xtrain=Xtrain[1:-1]\n",
    "#Ytrain=Ytrain[1:-1]\n",
    "#print(np.shape(Xtrain))\n",
    "#print(Xtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASE DE LA CAPA DE LA RED\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class neural_layer(object):\n",
    "    def __init__(self, n_conn, n_neur, activation=\"relu\"):\n",
    "        self.act = Funciones[activation]\n",
    "        self.activation=activation\n",
    "        self.random=self.act.Rand_init  \n",
    "        self.shape=(n_conn,n_neur)\n",
    "        self.Initialize()\n",
    "        \n",
    "    def show(self,Full=False):\n",
    "        print(f\"Pesos shape:{np.shape(self.W)} bias shape:{np.shape(self.b)} Activation:{self.activation}\")\n",
    "        print(f\"Activation:{self.activation}, Random:{self.random}\")\n",
    "        print(\"______________________\")\n",
    "        if Full:\n",
    "            print(f\"Pesos:\")\n",
    "            print(self.W)\n",
    "            print(\"#####\")\n",
    "            print(f\"Bias:\")\n",
    "            print(self.b)\n",
    "            \n",
    "    def Initialize(self):\n",
    "        #inicializa los pesos iniciales con aleatorios\n",
    "        self.b = np.random.uniform(*self.random,(1, self.shape[1]))      \n",
    "        self.W = np.random.uniform(*self.random,self.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "#CLASE RED NEURONAL MULTICAPA        \n",
    "class Neural_Net(object):\n",
    "    def __init__(self,Input,loss):\n",
    "        self.loss = Loss[loss]\n",
    "        self.Funcion_Loss=loss\n",
    "        self.Input=Input\n",
    "        self.NN=None;\n",
    "              \n",
    "    def Add_Layer(self,Num_neurons, function):\n",
    "        if self.NN is None:\n",
    "            self.NN=[]\n",
    "            self.NN.append(neural_layer(self.Input,Num_neurons,function))\n",
    "        else:\n",
    "            _,L_input=np.shape(self.NN[-1].W)\n",
    "            self.NN.append(neural_layer(L_input,Num_neurons,function))\n",
    "            \n",
    "    def Show_Model(self, Full=False):\n",
    "        print(f\"Input shape:{self.Input}, Loss: {self.Funcion_Loss}\")\n",
    "        for i,L in enumerate(self.NN):\n",
    "            print(F\"Layer_{i}:\")\n",
    "            L.show(Full)\n",
    "            \n",
    "            \n",
    "    # fucnción de predicción (fordware pass)    \n",
    "    def Predict(self,X):  \n",
    "      #sólo podemos pasar Numpy  \n",
    "      sx=np.shape(X)\n",
    "      X=X.reshape(1,sx[0])\n",
    "      if self.NN is None:\n",
    "          print(\"error in Predict Method ( not NEURAL network available)\")\n",
    "          return 0\n",
    "        \n",
    "      out = [(None, X)] #primer data necesario\n",
    "      # Forward pass\n",
    "      for l, layer in enumerate(self.NN):\n",
    "          z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "          a = self.NN[l].act.F(z)\n",
    "          out.append((z, a))\n",
    "      return out[-1][1]\n",
    "    \n",
    "    \n",
    "    # función retropropagación del error\n",
    "    def _backward_pass(self, X, Y,lr=0.01):\n",
    "      sx=np.shape(X)\n",
    "      sy=np.shape(Y)   \n",
    "      X=X.reshape(1,sx[0])\n",
    "      Y=Y.reshape(1,sy[0])\n",
    "\n",
    "      # Forward pass\n",
    "      out = [(None, X)] #primer data necesario\n",
    "      for l, layer in enumerate(self.NN):\n",
    "            z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "            a = self.NN[l].act.F(z)\n",
    "            out.append((z, a))\n",
    "\n",
    "      # Backward pass \n",
    "      deltas = []\n",
    "      for l in reversed(range(0, len(self.NN))):\n",
    "        z = out[l+1][0]\n",
    "        a = out[l+1][1]\n",
    "        if l == len(self.NN) - 1:\n",
    "            deltas.insert(0, self.loss.D(a, Y) * self.NN[l].act.D(a)) # La última capa\n",
    "        else:\n",
    "            deltas.insert(0, deltas[0] @ _W.T * self.NN[l-1].act.D(a))\n",
    "        _W = self.NN[l].W #los pesos en la capa superior\n",
    " \n",
    "        # Gradient descent. actualizamos pesos \n",
    "        self.NN[l].b = self.NN[l].b - (deltas[0]* lr)\n",
    "        self.NN[l].W = self.NN[l].W - (lr * (out[l][1].T @ deltas[0]))\n",
    "      return out[-1][1]\n",
    "\n",
    "    # función de entrenamiento de la red\n",
    "    def Train(self,X,Y,lr=0.01,epoch=10,batch_size=1):\n",
    "        H_loss = []\n",
    "        H_acc=[]\n",
    "        \n",
    "        # inicializamos las capas neuronales a valores ramdom del rango de la función\n",
    "        for Layer in self.NN:\n",
    "            Layer.Initialize()\n",
    "            \n",
    "        for i in range(epoch):\n",
    "            account=0\n",
    "            epoch_Loss=0\n",
    "            epoch_Acc=0\n",
    "            # Entrenemos a la red! con el dataset de validación\n",
    "            for j in range(len(X)):\n",
    "                pY = self._backward_pass(X[j,:], Y[j,:],lr)#fila, fila, learning rate\n",
    "                epoch_Loss+=self.loss.F(pY[0],Y[j,:])\n",
    "                if (Y[j,:]==np.round(pY)).all():#condicion de acertar\n",
    "                    epoch_Acc+=1\n",
    "            H_acc.append(epoch_Acc/len(Y)*100)    \n",
    "            H_loss.append(epoch_Loss/len(Y))#media del error\n",
    "            \n",
    "            #imprimimos por pantalla resultados\n",
    "            print(\"Epoch={}, Accurary={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "            clear_output(wait=True)\n",
    "        print(\"Epoch={}, Accuracy={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "        return H_loss,H_acc\n",
    "\n",
    "    \n",
    "# VISUALIZACIÓN Y TEST\n",
    "def Show_Loss_Acc(H_loss,H_acc):\n",
    "    plt.plot(range(len(H_loss)), H_loss,\"tab:blue\")\n",
    "    plt.ylabel(\"loss function \")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(H_acc)), H_acc, \"tab:red\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "       \n",
    "def print_predict(neural_net,X,Y):\n",
    "    for i in range(len(X)):\n",
    "        sal_float=neural_net.Predict(X[i])\n",
    "        sal=np.round(sal_float)\n",
    "        \n",
    "        if (Y[i]==np.round(sal)).all():\n",
    "            print(\"Input:{}-- Real:{} predict: {} predict_float:{}\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "        else:\n",
    "            print(\"\\x1b[31m Input:{}-- Real:{} predict: {} predict_float:{}\\x1b[0m\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIMOS LOS MODELOs\n",
    "def Model1():\n",
    "    red=Neural_Net(Input=15,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(30,\"relu\")\n",
    "    red.Add_Layer(3,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model2():\n",
    "    red=Neural_Net(Input=15,loss=\"mse\")\n",
    "    red.Add_Layer(8,\"tanh\")\n",
    "    red.Add_Layer(3,\"sigm\")\n",
    "    return red\n",
    "\n",
    "def Model3(): \n",
    "    red=Neural_Net(Input=15,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(16,\"sigm\")\n",
    "    red.Add_Layer(24,\"tanh\")\n",
    "    red.Add_Layer(8,\"relu\")\n",
    "    red.Add_Layer(3,\"softmax\")\n",
    "    return red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:15, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(15, 16) bias shape:(1, 16) Activation:sigm\n",
      "Activation:sigm, Random:(0, 1)\n",
      "______________________\n",
      "Layer_1:\n",
      "Pesos shape:(16, 24) bias shape:(1, 24) Activation:tanh\n",
      "Activation:tanh, Random:(-1, 1)\n",
      "______________________\n",
      "Layer_2:\n",
      "Pesos shape:(24, 8) bias shape:(1, 8) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Layer_3:\n",
      "Pesos shape:(8, 3) bias shape:(1, 3) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Input shape:15, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(15, 16) bias shape:(1, 16) Activation:sigm\n",
      "Activation:sigm, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.69408829 0.5247199  0.25263832 0.84875195 0.54978353 0.64645637\n",
      "  0.82772777 0.66301844 0.8396225  0.55962669 0.9374915  0.63418343\n",
      "  0.11133211 0.23915377 0.83943052 0.43209215]\n",
      " [0.72994379 0.01701492 0.62503007 0.09872721 0.75662406 0.36043682\n",
      "  0.55971044 0.96483254 0.62139171 0.20777559 0.84197406 0.24333107\n",
      "  0.44095167 0.20848297 0.56591879 0.29089769]\n",
      " [0.95792726 0.95547425 0.0743357  0.71404576 0.17375893 0.96280099\n",
      "  0.97133031 0.86146958 0.42405014 0.64541686 0.25589745 0.99380688\n",
      "  0.34675139 0.17699037 0.77408279 0.1128775 ]\n",
      " [0.92933989 0.34545433 0.29821464 0.89209026 0.17704142 0.56679047\n",
      "  0.70847078 0.02608935 0.41735072 0.41491849 0.43554849 0.4049828\n",
      "  0.48532595 0.67780121 0.53065331 0.06779985]\n",
      " [0.69137871 0.84442676 0.46287415 0.90606701 0.4357493  0.06912196\n",
      "  0.70957595 0.19467137 0.55745285 0.08451846 0.69723982 0.90165165\n",
      "  0.68184916 0.98334544 0.50548744 0.93962951]\n",
      " [0.8712237  0.12563122 0.71674811 0.06265359 0.43026549 0.45720374\n",
      "  0.8502382  0.22543722 0.18760523 0.79908954 0.93110335 0.45318145\n",
      "  0.61044243 0.79769759 0.20351519 0.87492129]\n",
      " [0.45936733 0.848133   0.67737994 0.08670202 0.81611304 0.01963475\n",
      "  0.03852668 0.60563874 0.0079395  0.17656321 0.15387072 0.33935631\n",
      "  0.84543973 0.5440108  0.96141472 0.42915187]\n",
      " [0.45398555 0.29860069 0.74151056 0.73935018 0.35081729 0.34565782\n",
      "  0.32475886 0.08667235 0.54874411 0.53427442 0.21020473 0.5390702\n",
      "  0.22218271 0.81173077 0.1311059  0.37526463]\n",
      " [0.77498353 0.01745037 0.21257351 0.48041285 0.84639873 0.24072539\n",
      "  0.8418517  0.66442578 0.82894549 0.91676875 0.95304456 0.79790966\n",
      "  0.5841441  0.79777849 0.1427052  0.65795921]\n",
      " [0.74994212 0.16997165 0.38222708 0.32260392 0.64091276 0.8425806\n",
      "  0.76714078 0.13084145 0.18777991 0.55739494 0.47099309 0.50607178\n",
      "  0.94186427 0.09625895 0.13420575 0.69933335]\n",
      " [0.8011885  0.81647243 0.45138266 0.1520883  0.94521537 0.65138696\n",
      "  0.6657456  0.10407614 0.07383494 0.5968461  0.39087782 0.39042677\n",
      "  0.00310914 0.82451239 0.34834244 0.4897631 ]\n",
      " [0.52144003 0.2361288  0.49417295 0.10670036 0.99874335 0.14591633\n",
      "  0.14484629 0.82157127 0.28489582 0.93643425 0.71624419 0.565359\n",
      "  0.31610978 0.37044573 0.16500579 0.57516087]\n",
      " [0.96341161 0.89450816 0.63379389 0.59864065 0.1465076  0.49493936\n",
      "  0.72101107 0.51401214 0.95437458 0.50193042 0.39571014 0.55133028\n",
      "  0.55454125 0.72275745 0.20193102 0.1840037 ]\n",
      " [0.46024859 0.57270579 0.85368429 0.73569488 0.50332341 0.482334\n",
      "  0.61637362 0.85313998 0.19120086 0.6838603  0.56894371 0.83562772\n",
      "  0.36157573 0.87239183 0.25365795 0.7982182 ]\n",
      " [0.16239952 0.12519498 0.70124551 0.81529713 0.07243317 0.5493535\n",
      "  0.37246981 0.55609683 0.58860766 0.40384881 0.66431709 0.16102799\n",
      "  0.9445167  0.84482704 0.58433088 0.40778642]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.16115644 0.11541966 0.35314238 0.43123046 0.18507855 0.95888714\n",
      "  0.22444226 0.21785884 0.75777602 0.54476099 0.02800878 0.11016774\n",
      "  0.11995164 0.00987959 0.1073141  0.2038432 ]]\n",
      "Layer_1:\n",
      "Pesos shape:(16, 24) bias shape:(1, 24) Activation:tanh\n",
      "Activation:tanh, Random:(-1, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[ 0.17713388  0.3311171   0.95415087  0.71372878  0.45176266 -0.12843064\n",
      "   0.38906687 -0.62823127  0.94627582  0.40348458  0.30926858 -0.24867851\n",
      "  -0.82564285  0.31617078  0.05495049  0.87227876 -0.77640039  0.76701879\n",
      "   0.71211148  0.64663473 -0.25146546 -0.18748214  0.46712641 -0.07961096]\n",
      " [-0.38194233  0.17268226 -0.12120066  0.34412759  0.29562135 -0.82687856\n",
      "  -0.04570331  0.06769867  0.73800293  0.27751568  0.42928396 -0.17395422\n",
      "   0.36239234 -0.08974325 -0.10687432 -0.46402025 -0.61753782 -0.77360526\n",
      "  -0.80271161 -0.86396615 -0.42083354  0.50869715  0.19606386 -0.07216762]\n",
      " [ 0.23531555  0.01262044 -0.37402334 -0.72393013  0.43735891  0.72410374\n",
      "   0.06517679 -0.48941164 -0.52770723 -0.70213012  0.38007604 -0.24665333\n",
      "   0.94920307  0.42687997 -0.86244271 -0.7834605   0.24978557  0.1203485\n",
      "   0.57414293 -0.89667974  0.08861577  0.6502959  -0.5222699  -0.78763034]\n",
      " [ 0.36904223  0.38540252 -0.26072805  0.8274694  -0.26820093 -0.8401485\n",
      "  -0.72769426  0.47609444  0.03716813 -0.19275338 -0.20962611 -0.52694505\n",
      "  -0.57996264  0.07665475 -0.4777329  -0.99104156  0.66179601 -0.61111739\n",
      "   0.18863293 -0.97953643 -0.29805137 -0.68798976  0.16652117  0.61343268]\n",
      " [ 0.96293964 -0.68129681 -0.80299119  0.27771271  0.22164822  0.22814307\n",
      "   0.37007347  0.99533111 -0.70644843  0.20631301  0.63771342 -0.32491132\n",
      "   0.70294028 -0.64582455 -0.71506009 -0.5852834   0.77600988  0.01331775\n",
      "   0.69122649 -0.03232609  0.3814089  -0.30232466 -0.6095548   0.29547177]\n",
      " [ 0.61952465 -0.97310334  0.85976104 -0.24545331  0.81251074  0.00867122\n",
      "  -0.02819804 -0.06576363  0.64708316 -0.47603368 -0.52951857  0.50229556\n",
      "  -0.38846505  0.38776705  0.18424067 -0.60069181 -0.19711006  0.85410742\n",
      "  -0.21682118 -0.97409297 -0.84963829  0.97874594 -0.28042095  0.28683556]\n",
      " [-0.58395794 -0.59532053  0.84430005  0.62769283  0.47334133  0.88820397\n",
      "  -0.7994294   0.33771313  0.88483808  0.72262743 -0.44188524 -0.46230173\n",
      "   0.57562638 -0.75107205 -0.02530492 -0.67062432 -0.72728062  0.14186257\n",
      "  -0.3218153  -0.62856048 -0.61104531 -0.64060497  0.2295988  -0.36674173]\n",
      " [ 0.10321979  0.10890796 -0.41374899  0.10615951  0.85044463  0.97890827\n",
      "  -0.49182326 -0.16466694 -0.05837343  0.61846678  0.64891423 -0.86757426\n",
      "  -0.1826377  -0.12021779 -0.9741948  -0.30894513 -0.91004134 -0.92855545\n",
      "  -0.25015307 -0.60734185 -0.10814484  0.24894179  0.55866353  0.69366037]\n",
      " [ 0.63388523  0.53082259  0.27533108  0.12720726  0.18691081 -0.02194712\n",
      "  -0.55224721  0.39930518 -0.02155824  0.9494451  -0.50019478 -0.59704294\n",
      "   0.02927469  0.46014283 -0.96275041  0.53515099  0.09549904  0.37695007\n",
      "  -0.54196152 -0.04577173  0.0229577   0.8618334   0.0240465   0.04213688]\n",
      " [-0.01577588 -0.78230314  0.16844504  0.75411384  0.98381222 -0.55369254\n",
      "  -0.10309117 -0.89153609  0.70617477  0.71839564  0.81921807 -0.45040472\n",
      "   0.78057568 -0.53854058 -0.42778156  0.02251583  0.3099308   0.65322361\n",
      "  -0.57139163 -0.57314577  0.22752127  0.89568725  0.5922706   0.33392634]\n",
      " [-0.67419036  0.78344183 -0.9475901   0.59363526  0.10584089  0.70480903\n",
      "   0.46451059 -0.36337386  0.36503413 -0.39848624  0.94800765  0.86549928\n",
      "   0.67482607 -0.42705313  0.02371521 -0.22515432 -0.57959838 -0.55439896\n",
      "   0.88543422 -0.91922155  0.63222759  0.53413075 -0.004739   -0.73765339]\n",
      " [-0.15406498  0.45303537 -0.86275415  0.4006968  -0.48074632 -0.1997995\n",
      "   0.97907328 -0.68627116 -0.28348867  0.68356392 -0.78077971 -0.31888884\n",
      "  -0.15820937  0.51507633 -0.10791094  0.88635991  0.79613001  0.89424068\n",
      "   0.83875901 -0.39093329 -0.61827821 -0.28890223 -0.93728206  0.2384605 ]\n",
      " [ 0.23620283  0.35292569  0.64207488  0.06688728  0.60312242  0.7549546\n",
      "  -0.37107338 -0.65770848  0.51417288 -0.97414607 -0.19490419  0.8462174\n",
      "   0.29035315  0.45742662 -0.17640386  0.01293707 -0.37445054  0.72389303\n",
      "   0.74682871 -0.48521279  0.62508342  0.25332144 -0.55156985 -0.35153351]\n",
      " [-0.24988978 -0.18569644  0.01928783 -0.606031    0.77992206 -0.43146401\n",
      "   0.04479319  0.45837438  0.60778699  0.86988689  0.0727172  -0.08607004\n",
      "   0.66730363 -0.69294345  0.92315927  0.4865433  -0.8235108  -0.84548421\n",
      "  -0.98778095  0.63423715  0.08309219 -0.35006926 -0.40203494 -0.3393212 ]\n",
      " [-0.21354259  0.17004844 -0.93922806 -0.91608268  0.5360046  -0.70340128\n",
      "   0.04967566 -0.97555352 -0.17856888 -0.43551771  0.30692375 -0.02573571\n",
      "  -0.52160032 -0.38985929 -0.62159548 -0.42845645 -0.14507904 -0.54645128\n",
      "  -0.58336097  0.64744717  0.2994893   0.36310363  0.81783945  0.68406679]\n",
      " [-0.84540926  0.98925954 -0.6105383   0.27080587 -0.01125806 -0.14323076\n",
      "   0.3937125  -0.52339761 -0.05173124  0.59091382  0.24504754  0.21056363\n",
      "  -0.86543953  0.68931576 -0.46088475  0.47678723  0.02301644 -0.40474039\n",
      "  -0.18811477  0.27057964  0.69790298  0.80937685 -0.80194656  0.07075544]]\n",
      "#####\n",
      "Bias:\n",
      "[[-0.72192376  0.52903683  0.81606571 -0.43385552  0.09538917 -0.40501661\n",
      "   0.52102769  0.48927936  0.28956758  0.31120062  0.38506978  0.54030695\n",
      "  -0.35965861 -0.68782556 -0.14613647  0.33916008 -0.48851684 -0.15264802\n",
      "   0.69632037 -0.49057203 -0.30518148  0.05501362  0.8299072   0.30138094]]\n",
      "Layer_2:\n",
      "Pesos shape:(24, 8) bias shape:(1, 8) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.85141749 0.48293506 0.9445967  0.80137793 0.2582554  0.10536707\n",
      "  0.16990742 0.70387482]\n",
      " [0.97305844 0.09040767 0.44972978 0.93278011 0.97982019 0.4779236\n",
      "  0.33037136 0.2265757 ]\n",
      " [0.61143796 0.56131384 0.68882821 0.69110669 0.53919937 0.75924006\n",
      "  0.52548381 0.18796658]\n",
      " [0.74369964 0.99338976 0.51904978 0.99093844 0.59506964 0.98291612\n",
      "  0.40862973 0.13018195]\n",
      " [0.16637434 0.6052357  0.43256019 0.93722516 0.77234029 0.20937213\n",
      "  0.84088996 0.0306531 ]\n",
      " [0.13280677 0.24382868 0.18867536 0.21719543 0.42529293 0.14582679\n",
      "  0.6634737  0.51070626]\n",
      " [0.52629472 0.57814075 0.57141798 0.85698334 0.79296919 0.80613468\n",
      "  0.20984135 0.17997496]\n",
      " [0.82015085 0.18884729 0.60771925 0.39978762 0.36618628 0.77674944\n",
      "  0.71611023 0.55191273]\n",
      " [0.63489751 0.94819452 0.31545997 0.53839021 0.91124192 0.5371282\n",
      "  0.22842401 0.8483958 ]\n",
      " [0.77133831 0.21114573 0.51625836 0.08214572 0.83311197 0.50112501\n",
      "  0.46138647 0.0221788 ]\n",
      " [0.83701638 0.86247604 0.02212894 0.33022698 0.16240893 0.52349117\n",
      "  0.14044591 0.41681397]\n",
      " [0.34708431 0.03478359 0.67521272 0.27379381 0.37124052 0.07977006\n",
      "  0.5342217  0.83106365]\n",
      " [0.73731258 0.37448042 0.30270934 0.24680318 0.16797632 0.87019036\n",
      "  0.56027599 0.72904844]\n",
      " [0.59314909 0.84432568 0.74623152 0.73479632 0.56061658 0.04976228\n",
      "  0.70338835 0.2079399 ]\n",
      " [0.63621216 0.64547921 0.26353643 0.92394863 0.60263715 0.04440447\n",
      "  0.58381138 0.62488409]\n",
      " [0.52809898 0.9517796  0.2380229  0.14638555 0.93832689 0.54014305\n",
      "  0.18598651 0.91829124]\n",
      " [0.83265381 0.99525685 0.39966089 0.40808355 0.30275272 0.04017909\n",
      "  0.88157234 0.66044996]\n",
      " [0.94624485 0.18734226 0.1907201  0.43266937 0.93370119 0.47547714\n",
      "  0.28289428 0.82235981]\n",
      " [0.28053447 0.20628205 0.81755321 0.43987953 0.66221753 0.05696872\n",
      "  0.55272944 0.80618091]\n",
      " [0.72828128 0.64757426 0.42836633 0.08543352 0.18141762 0.14466959\n",
      "  0.70584405 0.29700925]\n",
      " [0.15618127 0.81720807 0.02582591 0.69549153 0.66407131 0.20558808\n",
      "  0.2245371  0.19305959]\n",
      " [0.52665549 0.42381825 0.64932001 0.92311909 0.42629893 0.10354595\n",
      "  0.538152   0.26830357]\n",
      " [0.71927868 0.93880928 0.80813084 0.32367045 0.96848713 0.71259239\n",
      "  0.54783706 0.72705703]\n",
      " [0.2624742  0.5143499  0.57357529 0.50967266 0.493681   0.30228048\n",
      "  0.94378077 0.40338157]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.92209723 0.63316897 0.97409683 0.3432538  0.00955852 0.09036645\n",
      "  0.44173594 0.47321893]]\n",
      "Layer_3:\n",
      "Pesos shape:(8, 3) bias shape:(1, 3) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.92918668 0.51067476 0.20493213]\n",
      " [0.87568692 0.10895866 0.38587028]\n",
      " [0.40646608 0.85384243 0.75056145]\n",
      " [0.46934978 0.86217893 0.71093541]\n",
      " [0.18241603 0.51916399 0.58285076]\n",
      " [0.74533539 0.59522292 0.31254153]\n",
      " [0.38394569 0.59527497 0.24523038]\n",
      " [0.21094522 0.26024102 0.2843904 ]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.23591548 0.61115386 0.57628264]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m cnn\u001b[38;5;241m.\u001b[39mShow_Model()\n\u001b[0;32m      3\u001b[0m cnn\u001b[38;5;241m.\u001b[39mShow_Model(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "cnn=Model3()\n",
    "cnn.Show_Model()\n",
    "cnn.Show_Model(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,3) (1,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss,accuracy\u001b[38;5;241m=\u001b[39m\u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Show_Loss_Acc(loss,accuracy)\n",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36mNeural_Net.Train\u001b[1;34m(self, X, Y, lr, epoch, batch_size)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Entrenemos a la red! con el dataset de validación\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[1;32m--> 117\u001b[0m     pY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#fila, fila, learning rate\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     epoch_Loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mF(pY[\u001b[38;5;241m0\u001b[39m],Y[j,:])\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (Y[j,:]\u001b[38;5;241m==\u001b[39mnp\u001b[38;5;241m.\u001b[39mround(pY))\u001b[38;5;241m.\u001b[39mall():\u001b[38;5;66;03m#condicion de acertar\u001b[39;00m\n",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36mNeural_Net._backward_pass\u001b[1;34m(self, X, Y, lr)\u001b[0m\n\u001b[0;32m     90\u001b[0m a \u001b[38;5;241m=\u001b[39m out[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 92\u001b[0m     deltas\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN[l]\u001b[38;5;241m.\u001b[39mact\u001b[38;5;241m.\u001b[39mD(a)) \u001b[38;5;66;03m# La última capa\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     deltas\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, deltas[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m@\u001b[39m _W\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mact\u001b[38;5;241m.\u001b[39mD(a))\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(yscore, yreal)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# funciones de coste\u001b[39;00m\n\u001b[0;32m     40\u001b[0m mse\u001b[38;5;241m=\u001b[39mfunction(funcion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m Yp, Yr: np\u001b[38;5;241m.\u001b[39mmean((Yp \u001b[38;5;241m-\u001b[39m Yr) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) ,\n\u001b[0;32m     41\u001b[0m                  derivative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m Yp, Yr: (Yp \u001b[38;5;241m-\u001b[39m Yr))\n\u001b[0;32m     43\u001b[0m cross_entropy\u001b[38;5;241m=\u001b[39mfunction(funcion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m yscore,yreal:\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(yreal\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(yscore))\u001b[38;5;241m/\u001b[39myscore\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m---> 44\u001b[0m                        derivative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m yscore,yreal:\u001b[43myscore\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43myreal\u001b[49m)\n\u001b[0;32m     46\u001b[0m Funciones\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m:relu,\n\u001b[0;32m     47\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigm\u001b[39m\u001b[38;5;124m\"\u001b[39m:sigm,\n\u001b[0;32m     48\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m:relu,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineal\u001b[39m\u001b[38;5;124m\"\u001b[39m:lineal,\n\u001b[0;32m     52\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:softmaxf}\n\u001b[0;32m     54\u001b[0m Loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m:mse,\n\u001b[0;32m     55\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m:cross_entropy}\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,3) (1,2) "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "loss,accuracy=cnn.Train(Xtrain,Ytrain,0.2,300)\n",
    "Show_Loss_Acc(loss,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_25176\\1201046261.py:147: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if (Y[i]==np.round(sal)).all():\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprint_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::::::::::::::::::::::::::::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mround(cnn\u001b[38;5;241m.\u001b[39mPredict(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.51\u001b[39m,\u001b[38;5;241m0.35\u001b[39m,\u001b[38;5;241m0.14\u001b[39m,\u001b[38;5;241m0.02\u001b[39m])))\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mprint_predict\u001b[1;34m(neural_net, X, Y)\u001b[0m\n\u001b[0;32m    144\u001b[0m sal_float\u001b[38;5;241m=\u001b[39mneural_net\u001b[38;5;241m.\u001b[39mPredict(X[i])\n\u001b[0;32m    145\u001b[0m sal\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mround(sal_float)\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43msal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m():\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-- Real:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m predict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m predict_float:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(X[i],Y[i],sal,np\u001b[38;5;241m.\u001b[39mround(sal_float,\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "print_predict(cnn,Xtrain,Ytrain)\n",
    "print(\"::::::::::::::::::::::::::::\")\n",
    "\n",
    "\n",
    "np.round(cnn.Predict(np.array([0.51,0.35,0.14,0.02])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
