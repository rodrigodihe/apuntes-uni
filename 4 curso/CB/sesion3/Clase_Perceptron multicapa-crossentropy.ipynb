{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjoklEQVR4nO3de5Ac5Xnv8e+zszftrm6LVhd0QUJSABEbAWuBzfGVSxDnFMKJSeQ6xxDHFUHKOg7HdmIlroqp5BwXcXBccYxRRKwETmEUHJugIrIFJgYfB0O0wkJIAqHVfe83sau9zc7uPueP6SXDMKudkXamZ3d+n6qpmXn7fbuf7pX6mX777W5zd0REpPAUhR2AiIiEQwlARKRAKQGIiBQoJQARkQKlBCAiUqCKww4gE/PmzfPly5eHHYaIyJSyd+/eDnevSS6fUglg+fLl1NXVhR2GiMiUYmYnU5WrC0hEpEApAYiIFCglABGRAqUEICJSoJQAREQKlBKAiEiBUgIQESlQSgAiInmstWeQB3cf5mh776TPWwlARCSPHe/o4zs/q6ele3DS560EICKSxzp7hwC4qKp00uetBCAikse6+qIAVFcqAYiIFJSO4AigukIJQESkoHT2RZlbUUJxZPJ310oAIiJ5rLN3iIuqyrIy77QSgJndamaHzazezLakmH65mf3SzKJm9uWE8svMbF/Cq8fM7gum3W9mjQnTbpu0tRIRmSY6+4a4KAv9/5DG8wDMLAI8BNwMNAB7zGynux9KqNYFfAG4I7Gtux8G1ibMpxF4KqHKt9z9wQuIX0RkWuvsjXLZwplZmXc6RwDrgHp3P+buQ8AOYENiBXdvc/c9QOwc87kROOruKR9MICIi7xU/AgivC2gxcDrhe0NQlqmNwBNJZZvNbL+ZbTezuakamdkmM6szs7r29vbzWKyIyNQUGxnl7f5YVq4BgPQSgKUo80wWYmalwO3ADxKKHwZWEu8iaga+maqtu29z91p3r62pec8jLUVEpq0z/WMXgYV3BNAALE34vgRoynA564FX3b11rMDdW919xN1HgUeIdzWJiEjgnauAs3QSOJ0EsAdYbWYrgl/yG4GdGS7n0yR1/5jZooSvnwQOZDhPEZFpLdsJYMJRQO4+bGabgd1ABNju7gfN7N5g+lYzWwjUAbOA0WCo5xp37zGzCuIjiO5JmvU3zGwt8e6kEymmi4gUtM7gNhDZ6gKaMAEAuPsuYFdS2daEzy3Eu4ZSte0HLkpR/pmMIhURKTBjt4GYF+JJYBERCUFXX5TiImNWeUlW5q8EICKSpzp7h5hbWUpRUarBmBdOCUBEJE919GbvNhCgBCAikrc6+6LMy9IJYFACEBHJW119Q1m7ChiUAERE8lZnb/buAwRKACIieWkwNkJvdFhHACIihaazL7tXAYMSgIhIXurqze6N4EAJQEQkL3W8cxsIHQGIiBSUbN8IDpQARETyUmdvdm8EB0oAIiJ5qatviLLiIipLI1lbhhKAiEge6ugdYl5VGWbZuQ8QKAGIiOSlzr5oVk8AgxKAiEhe6uwdojqLJ4BBCUBEJC919WX3NhCgBCAiknfcnY7eaNaeBDYmrQRgZrea2WEzqzezLSmmX25mvzSzqJl9OWnaCTN73cz2mVldQnm1mT1nZkeC97kXvjoiIlNf39AI0eHR8M8BmFkEeAhYD6wBPm1ma5KqdQFfAB4cZzYfd/e17l6bULYFeN7dVwPPB99FRAre2DUA1XnQBbQOqHf3Y+4+BOwANiRWcPc2d98DxDJY9gbg0eDzo8AdGbQVEZm2Ot65D1ApI93ddD/9NLG2tklfTjoJYDFwOuF7Q1CWLgeeNbO9ZrYpoXyBuzcDBO/zUzU2s01mVmdmde3t7RksVkRkaho7AphXWUb0yBGavrKF6FtHJn056SSAVFcheAbLuMHdryHehfR5M/tIBm1x923uXuvutTU1NZk0FRGZklp7BgFYMLuMoYYGAEoWXzzpy0knATQASxO+LwGa0l2AuzcF723AU8S7lABazWwRQPA++cc3IiJTUEvPIJEi46LKMmINjQCULM6k4yU96SSAPcBqM1thZqXARmBnOjM3s0ozmzn2GbgFOBBM3gncHXy+G3g6k8BFRKar1p4o82eWESkyYo2NFM+fT1Hp5I8IKp6ogrsPm9lmYDcQAba7+0EzuzeYvtXMFgJ1wCxg1MzuIz5iaB7wVHAvi2Lg++7+k2DWDwBPmtnngFPAnZO6ZiIiU1RrzyDzZ5UDEGtooGTJkqwsZ8IEAODuu4BdSWVbEz63EO8aStYDXDXOPDuBG9OOVESkQLR0D3JpTSUAscZGZtRem5Xl6EpgEZE809ozyMJZ5XgsRqylJSv9/6AEICKSVwaGRugZHGb+rHJiLS0wOkpplrqAlABERPJISzAEdOGscmKNYyOAlABERKa9sWsAFs4uJzZ2DcASdQGJiEx771wENquMocZGiEQoWbgwK8tSAhARySP/mQDKiTU0UrJgAVac1oDNjCkBiIjkkZbuKBWlEarKirN6DQAoAYiI5JWxIaBm8auAlQBERApEa88gC2aVMxqNMtzWlpWbwI1RAhARySMtPYMsmFVGrCl+z81sXQMASgAiInnD3WnribJgdnlW7wI6RglARCRPnOmPMTQyGlwENnYNgI4ARESmvZbuhCGgjY1QUkLx/JQPS5wUSgAiInki8RqAoYYGSi5ehBVlbzetBCAikicSrwKONTZRmqV7AI1RAhARyRNjN4KbP7M86xeBgRKAiEjeaO0ZZF5VKcXRAUa6urI6AgiUAERE8kb8WcDl71wDkK27gI5JKwGY2a1mdtjM6s1sS4rpl5vZL80samZfTihfamY/M7M3zOygmf1hwrT7zazRzPYFr9smZ5VERKamlu5BFs6OnwAGKM3yEcCEt5gzswjwEHAz0ADsMbOd7n4ooVoX8AXgjqTmw8CX3P1VM5sJ7DWz5xLafsvdH7zQlRARmQ5aewa5aukchk4eBKDkkkuyurx0jgDWAfXufszdh4AdwIbECu7e5u57gFhSebO7vxp8Pgu8AWQ3pYmITEFDw6N09g3FRwCdOkXRrFlE5szJ6jLTSQCLgdMJ3xs4j524mS0HrgZeSSjebGb7zWy7mc0dp90mM6szs7r29vZMFysiMiW0nf3PR0EOnThJ6SWXYGZZXWY6CSBVBJ7JQsysCvghcJ+79wTFDwMrgbVAM/DNVG3dfZu717p7bU1NTSaLFRGZMt51EdipU5QuW5b1ZaaTABqApQnflwBN6S7AzEqI7/wfd/cfjZW7e6u7j7j7KPAI8a4mEZGC1NoTBWDBjAixpiZKs9z/D+klgD3AajNbYWalwEZgZzozt/jxy/eAN9z9r5OmLUr4+kngQHohi4hMP41nBgCY39cJo6OUXpL9I4AJRwG5+7CZbQZ2AxFgu7sfNLN7g+lbzWwhUAfMAkbN7D5gDfB+4DPA62a2L5jln7r7LuAbZraWeHfSCeCeSVwvEZEppeFMPzPLiilrid8GOhdHAGk9aTjYYe9KKtua8LmFeNdQsl+Q+hwC7v6Z9MMUEZneTp8ZYEl1BUOnjgLZHwIKuhJYRCQvNJzpZ8ncGTkbAgpKACIioXN3TncNsHRuRXwI6LJlWR8CCkoAIiKh6+wbYiA2wtLqGfEhoDno/gElABGR0DUEI4CWVJXkbAgoKAGIiITudFc/AEsGu3I2BBSUAEREQjd2BDCvO367Gx0BiIgUiNNn+plbUUJRU/y2a7kYAgpKACIioTvd1c/S6oqcDgEFJQARkdA1nhlgydwZOR0CCkoAIiKhGh11Gs4E1wCcPJmz/n9QAhARCVV7b5ShkVGWVkWINTfnbAQQKAGIiIRqbAjoslh3MARURwAiIgVhbAjowrMdQO6GgIISgIhIqMaOAGa3x28DnashoKAEICISqtNn+qmZWcbI8eNE5s2jeG7Kx6NnhRKAiEiI4iOAZjB09ChlK1fmdNlKACIiITp9pp8lc2YQVQIQESkcwyOjNL89yOrIAKO9vZSuysMEYGa3mtlhM6s3sy0ppl9uZr80s6iZfTmdtmZWbWbPmdmR4D13HV8iInmgpWeQ4VFneV8bAGUrV+V0+RMmADOLAA8B64k/6P3TZrYmqVoX8AXgwQzabgGed/fVwPPBdxGRgnG6Kz4EdNGZFgDK8vAIYB1Q7+7H3H0I2AFsSKzg7m3uvgeIZdB2A/Bo8PlR4I7zWwURkamp4UwwBLTtNJHZs4lUV+d0+ekkgMXA6YTvDUFZOs7VdoG7NwME7/NTzcDMNplZnZnVtbe3p7lYEZH8d7Kzn0iRUXz6JKWrVuXsJnBj0kkAqSLyNOd/IW3jld23uXutu9fW1NRk0lREJK8dbe/lkuoZxEIYAQTpJYAGYGnC9yVAU5rzP1fbVjNbBBC8t6U5TxGRaeFoey+/XjnKSHd3zvv/Ib0EsAdYbWYrzKwU2AjsTHP+52q7E7g7+Hw38HT6YYuITG3DI6Oc6OjnfcNdAJSGcARQPFEFdx82s83AbiACbHf3g2Z2bzB9q5ktBOqAWcComd0HrHH3nlRtg1k/ADxpZp8DTgF3TvK6iYjkrYYzAwyNjLKiNxgCuiq3Q0AhjQQA4O67gF1JZVsTPrcQ795Jq21Q3gncmEmwIiLTxdH2XgDmdzVTVFVF8fyU42CyKq0EICIik2ssAVQ2nyKycmXORwCBbgUhIhKKo219zKsqZeTE8ZzfAmKMEoCISAiOdfRyZRWMdHTk/BYQY5QARERCcLS9j7WjbwO5vwXEGJ0DEBHJsa6+Ibr6hlhVFB8BVHqpuoBERArCseAE8KKOBoqqqii5eFEocSgBiIjk2NgIoJmnj1F2+WVYUTi7YiUAEZEcO9rex4wI+NEjlF+RfHf93FECEBHJsaNtvdSW9OEDA5RfcUVocSgBiIjk2NH2Xq6Nxm9vX75GCUBEpCBEh0c41dXP6p5GKCmh7NJLQ4tFCUBEJIdOdfYz6rCg7RRlq1dhpaWhxaIEICKSQ0fbe8GditPHQu3/ByUAEZGcqm/r5aLBHuztM5RfrgQgIlIw3mg+y/UjHUC4J4BBCUBEJKcONnVzTawdzCi77PJQY1ECEBHJkbODMU509rOqu5HSZcuIVFWGGo8SgIhIjrzZchaA6uYTlIV8AhjSTABmdquZHTazejPbkmK6mdm3g+n7zeyaoPwyM9uX8OoJnheMmd1vZo0J026b1DUTEckzBxu7qRwaoLi1OfQRQJDG7aDNLAI8BNwMNAB7zGynux9KqLYeWB28rgMeBq5z98PA2oT5NAJPJbT7lrs/OAnrISKS9w429XB1LH4L6LBPAEN6RwDrgHp3P+buQ8AOYENSnQ3AYx73MjDHzJLvb3ojcNTdT15w1CIiU9DBph7WDQcjgPLgCCCdBLAYOJ3wvSEoy7TORuCJpLLNQZfRdjObm2rhZrbJzOrMrK69vT2NcEVE8s/Q8ChH2s5yRXcDxQsWUDxvXtghpZUAUj2q3jOpY2alwO3ADxKmPwysJN5F1Ax8M9XC3X2bu9e6e21NTU0a4YqI5J+3Ws8SG3EWnH6LGVdfHXY4QHoJoAFYmvB9CdCUYZ31wKvu3jpW4O6t7j7i7qPAI8S7mkREpqVDzT1UD3RT0t7KjLVXhR0OkF4C2AOsNrMVwS/5jcDOpDo7gbuC0UDXA93u3pww/dMkdf8knSP4JHAg4+hFRKaIQ009rD0b7ymvWLs23GACE44CcvdhM9sM7AYiwHZ3P2hm9wbTtwK7gNuAeqAf+OxYezOrID6C6J6kWX/DzNYS7yo6kWK6iMi0cbCpm1sGm7DSUsrWhPcUsEQTJgAAd99FfCefWLY14bMDnx+nbT9wUYryz2QUqYjIFDU66hxq6uF/dp6k/MorKQrxFtCJdCWwiEiWnezqZ2ggykWNx/LmBDAoAYiIZN3Bpm5WdjdSNBzLmxPAoAQgIpJ1B5t6uPJM/BrYGXlyAhiUAEREsu5Xp86wrr+RksWLKZk/P+xw3qEEICKSRUPDo+w7dYZV7cfz6tc/KAGIiGTVwaZuZvZ0UdHTpQQgIlJI9p48wxVdQf9/Ho0AAiUAEZGs2nOii3X9DVh5OeWX/VrY4byLEoCISJa4O3UnznB1Rz0V11yDlZSEHdK7KAGIiGTJ8Y4+Rjs7qG5roPJDHww7nPdQAhARyZK6k2dY214PQMUHlQBERApG3Yku1p2pp2j27Lx4AlgyJQARkSypO97Fte31VH7wg1hR/u1u8y8iEZFpoKM3SvTECWae7aIyD7t/QAlARCQr6k6c4er2IwB5eQIYlABERLJi78kuru04QvGSJZQuXTpxgxAoAYiIZMFLb7WxtvMoVXna/QNKACIik66le5DhNw5RHh3I2+4fSDMBmNmtZnbYzOrNbEuK6WZm3w6m7zezaxKmnTCz181sn5nVJZRXm9lzZnYkeJ87OaskIhKuF99qe6f/v+L660OOZnwTJgAziwAPAeuBNcCnzSz5icbrgdXBaxPwcNL0j7v7WnevTSjbAjzv7quB54PvIiJT3guH2/lQx1uUrVlD8dz8/W2bzhHAOqDe3Y+5+xCwA9iQVGcD8JjHvQzMMbNFE8x3A/Bo8PlR4I70wxYRyU+xkVFe33+MVR3HmXnTjWGHc07pJIDFwOmE7w1BWbp1HHjWzPaa2aaEOgvcvRkgeE/5mBwz22RmdWZW197enka4IiLhefXkGd538jXMnZk33RR2OOeUTgKwFGWeQZ0b3P0a4t1Enzezj2QQH+6+zd1r3b22pqYmk6YiIjn3wlvt3NB8gOKlyyhbvTrscM4pnQTQACQOYl0CNKVbx93H3tuAp4h3KQG0jnUTBe9tmQYvIpJvXt5/krUd9cy65SbMUv02zh/pJIA9wGozW2FmpcBGYGdSnZ3AXcFooOuBbndvNrNKM5sJYGaVwC3AgYQ2dwef7waevsB1EREJVWvPIHNe+w8ioyN53/0DUDxRBXcfNrPNwG4gAmx394Nmdm8wfSuwC7gNqAf6gc8GzRcATwVZsBj4vrv/JJj2APCkmX0OOAXcOWlrJSISghcPt/Oh5tfhonnMuOqqsMOZ0IQJAMDddxHfySeWbU347MDnU7Q7BqTcCu7eCeT3KXIRkQy8+HoDv992mDmf+s28vPtnsvyPUERkCuiNDtPzi19QNjzEzJvzv/sHlABERCbFc4da+MDp/XjVTCrXrZu4QR5QAhARmQS7/uM4H25+ndk335R3D38fjxKAiMgF6uyNws9/RvlwlLm/9Zthh5M2JQARkQu060ALN514BRYvYca114YdTtqUAERELtAvXtzH+zuPMe/O38r7i78SKQGIiFyAxrcHmP/ST3ErYs4dd4QdTkaUAERELsAzvzrNTafqiKy7jpKFC8MOJyNKACIi58ndOfDMvzF/4G0WbZx6NzNQAhAROU+vHO/iitd+znBlFVWf+ETY4WRMCUBE5Dz984/38uHG16j+5B0UlZWFHU7GlABERM5D49sDzPnxjygyqPnd3w07nPOiBCAich6e+LdDrD/xMqU33ULpkuSHJE4NSgAiIhkajI3Q/eSTVAxHWXrv74cdznlTAhARydDOPce55c0XiK2tpXzNmrDDOW9KACIiGRgddQ489gPmDfZw6eZ7wg7ngigBiIhkYNdrDdxQ9xMGL1lJ5Q03hB3OBVECEBFJ0/DIKC8/9CjLettY8cUvTKn7/qSSVgIws1vN7LCZ1ZvZlhTTzcy+HUzfb2bXBOVLzexnZvaGmR00sz9MaHO/mTWa2b7gddvkrZaIyOR76qUjrN+zk+jlv87sW24OO5wLNuEzgc0sAjwE3Aw0AHvMbKe7H0qoth5YHbyuAx4O3oeBL7n7q2Y2E9hrZs8ltP2Wuz84easjIpIdg7ERjn7n7/j16Fku+dpXp/yvf0jvCGAdUO/ux9x9CNgBbEiqswF4zONeBuaY2SJ3b3b3VwHc/SzwBjA1B8yKSEH7we5f8RsHfkr0w5+g4uq1YYczKdJJAIuB0wnfG3jvTnzCOma2HLgaeCWheHPQZbTdzOamWriZbTKzOjOra29vTyNcEZHJ9Xb/EL0PP0SJj7Lmz97TCz5lpZMAUh3neCZ1zKwK+CFwn7v3BMUPAyuBtUAz8M1UC3f3be5e6+61NTU1aYQrIjK5/v6hH/GRo69Q9Fu/Q+nSpWGHM2nSSQANQOIaLwGa0q1jZiXEd/6Pu/uPxiq4e6u7j7j7KPAI8a4mEZG88ovXT3P1ju8wcNF8Lt/yxbDDmVTpJIA9wGozW2FmpcBGYGdSnZ3AXcFooOuBbndvtvhZku8Bb7j7Xyc2MLNFCV8/CRw477UQEcmCgaERXvva17m4r5OVf/UARZWVYYc0qSYcBeTuw2a2GdgNRIDt7n7QzO4Npm8FdgG3AfVAP/DZoPkNwGeA181sX1D2p+6+C/iGma0l3lV0Apjal9SJyLTz2Nan+MShF4je/inmfuj6sMOZdOae3J2fv2pra72uri7sMESkALy07zjR3/sfVMwo5QPP/StFFRVhh3TezGyvu9cml094BCAiUmgaOns59b++yJWD3Sze+o9Teud/LroVhIhIgsHYCM9s/ipXNb9J2Ze+QvW69/xwnjaUAEREAu7OY3++lY/+6lnO3rqBX/vcZ8IOKauUAEREAo9/94dc98OtdKy8kg/81V+EHU7WKQGIiABPbnuKK7/755ytWcR1j23DSkrCDinrlABEpOA99Q87Wf03X6OvegG1//x9Si+qDjuknNAoIBEpWO7Ok3/7BL/2dw/QN6eGa//5ccpr5oUdVs4oAYhIQYrGRvinL32da599go5Fy7n2+//AjAXzww4rp5QARKTgtHd089NNX+QDh16i+eob+Oj3vk1kmo71PxedAxCRgvLC0y+w/7bbWXvoJdo/dRcf//4jBbnzBx0BiEiB6O7p4yd//H+48oV/oadqDkXf/A4f+a83hh1WqJQARGRaiw2PsPu732fmo1t5f18Xp9Z9go/8zdeZMXd22KGFTglARKal4ZFR/t8T/8rAI1tZ2XqMlnlLGPna/fzG7VP/Ye6TRQlARKaVgf5BXty2g6IfPM7SzgberphNxx/8ER/9/F0UFWuXl0hbQ0SmPHdn/4t1HH1sB4v3vsgl0T5a5i6i7Q/+iA/d898pKS8LO8S8pAQgIlNSbCjGvmf/ncZndjP7V79kYXcrq4oinL68lqLf+RQf/dR6iiKRsMPMa0oAIjIlDPQN8OZLr9L485cZ/dVeFp18k6rYACutiIZlV9B4x51c+9nf5v0La8IOdcpQAhCRvDIyPELL8QZO7ztE18E3idUfZcbJehZ2NFDuI6wE2mbV0Lz2g8y+4Qau/tR63jdvbthhT0lpJQAzuxX4G+LPBP57d38gaboF028j/kzg33X3V8/V1syqgX8ClhN/JvBvu/uZC18lEclXQ4NRuprb6Wpoobuplb7mNgabmhlpbSHS0UZFVxvV3e2UjQ4zG5gNnC2rpHP+Mk5+/HZmX/1+Vn3seq5YvTzkNZkeJkwAZhYBHgJuBhqAPWa2090PJVRbD6wOXtcBDwPXTdB2C/C8uz9gZluC71+ZvFUTkfGMjo4yOjLKyPAwI8MjDMeG45+HhhkeGmI4NsxwNMZwbIhYdIiRaIzYYJThwSjD0aH4+8AAw4NRRgYGGe3vZ2RwAO8fwPv7YaAfGxigeKCXkoE+ygb7qYz2UREbBMCAOcEL4GxpBT0zq+mruZjeqz5A6bJlVF++iuXXvo/Lly0i/htTJls6RwDrgHp3PwZgZjuADUBiAtgAPObxJ8y/bGZzzGwR8V/347XdAHwsaP8o8AJZSgDPfPl/U/Hv/5aNWcuFcA87gvfIeDeTsA7GOdYnYdK76iWXB/OzhHkn1rexMnfA36ln7ljw3Tw+n6JgfoZTNDpKEUE9dyLnijWFSPCaSMwiDJaUES0pZ6isnFh5JdHZ1QwsWsqZWXMomjOHkrlzKJ9fw8yLFzBn8UIWXrqUytlVGcUjkyOdBLAYOJ3wvYH4r/yJ6iyeoO0Cd28GcPdmM0t5Gz4z2wRsAli2bFka4b5X6fwaehcuPa+2km15+Msu05ASf52e85eqpfz47nJ7Zx5uCdMSyt/1fdxX0X9+LirCioLvkSIoKgIrwiKReHmkCCuKYCUlWHEEixRTVFKMFRcTKSmmqLSUSGkpkbISisvKKCkvo7i8nLLKcsoqKyirKGfGrCpmVFVQquGWU0o6CSDVv+jknw/j1Umn7Tm5+zZgG0Btbe15/WS85Y/vAe45n6YiItNWOncDbQASfz4vAZrSrHOutq1BNxHBe1v6YYuIyIVKJwHsAVab2QozKwU2AjuT6uwE7rK464HuoHvnXG13AncHn+8Gnr7AdRERkQxM2AXk7sNmthnYTfw80HZ3P2hm9wbTtwK7iA8BrSc+DPSz52obzPoB4Ekz+xxwCrhzUtdMRETOyTwPR2KMp7a21uvq6sIOQ0RkSjGzve5em1yuJ4KJiBQoJQARkQKlBCAiUqCUAERECtSUOglsZu3AyfNsPg/omMRwJoviyoziyoziyky+xgUXFtsl7v6e+2RPqQRwIcysLtVZ8LAprsworsworszka1yQndjUBSQiUqCUAEREClQhJYBtYQcwDsWVGcWVGcWVmXyNC7IQW8GcAxARkXcrpCMAERFJoAQgIlKgplUCMLM7zeygmY2aWW3StD8xs3ozO2xmvzFO+2oze87MjgTvc7MQ4z+Z2b7gdcLM9o1T74SZvR7Uy/od8MzsfjNrTIjttnHq3Rpsw/rgWc7ZjuuvzOxNM9tvZk+Z2Zxx6uVke020/sEt0b8dTN9vZtdkK5aEZS41s5+Z2RvBv/8/TFHnY2bWnfD3/bNsxxUs95x/l5C212UJ22GfmfWY2X1JdXKyvcxsu5m1mdmBhLK09kOT8n/R3afNC7gCuIz484VrE8rXAK8BZcAK4CgQSdH+G8CW4PMW4C+zHO83gT8bZ9oJYF4Ot939wJcnqBMJtt2lQGmwTddkOa5bgOLg81+O9zfJxfZKZ/2J3xb9x8Sfhnc98EoO/naLgGuCzzOBt1LE9THgmVz9e0r37xLG9krxN20hfqFUzrcX8BHgGuBAQtmE+6HJ+r84rY4A3P0Ndz+cYtIGYIe7R939OPHnFqwbp96jwedHgTuyEijxXz7AbwNPZGsZWbAOqHf3Y+4+BOwgvs2yxt2fdffh4OvLxJ8qF5Z01n8D8JjHvQzMCZ54lzXu3uzurwafzwJvEH8e91SQ8+2V5EbgqLuf7x0GLoi7/xzoSipOZz80Kf8Xp1UCOIfxHlqf7F0PqgdSPqh+knwYaHX3I+NMd+BZM9trZpuyGEeizcFh+PZxDjvT3Y7Z8nvEfy2mkovtlc76h7qNzGw5cDXwSorJHzSz18zsx2Z2ZY5CmujvEva/qY2M/yMsjO0F6e2HJmW7pfNQ+LxiZj8FFqaY9FV3H++xkhf8cPpMpBnjpzn3r/8b3L3JzOYDz5nZm8GvhazEBTwM/AXx7fIXxLunfi95FinaXvB2TGd7mdlXgWHg8XFmM+nbK1WoKcqS1z+n/9betWCzKuCHwH3u3pM0+VXi3Ry9wfmdfwFW5yCsif4uYW6vUuB24E9STA5re6VrUrbblEsA7n7TeTRL58H2EDyo3t2b7QIeVD9RjGZWDPwmcO055tEUvLeZ2VPED/kuaIeW7rYzs0eAZ1JMSnc7TmpcZnY38N+AGz3oAE0xj0nfXimks/5Z2UYTMbMS4jv/x939R8nTExOCu+8ys++a2Tx3z+qNz9L4u4SyvQLrgVfdvTV5QljbK5DOfmhStluhdAHtBDaaWZmZrSCeyf9jnHq5eFD9TcCb7t6QaqKZVZrZzLHPxE+EHkhVd7Ik9bt+cpzl7QFWm9mK4NfTRuLbLJtx3Qp8Bbjd3fvHqZOr7ZXO+u8E7gpGt1wPdI8dzmdLcD7pe8Ab7v7X49RZGNTDzNYR/7/fmeW40vm75Hx7JRj3KDyM7ZUgnf3Q5PxfzPZZ7ly+iO+4GoAo0ArsTpj2VeJnzQ8D6xPK/55gxBBwEfA8cCR4r85SnP8I3JtUdjGwK/h8KfGz+q8BB4l3hWR72/1f4HVgf/APaVFyXMH324iPMjmao7jqifd17gteW8PcXqnWH7h37O9J/ND8oWD66ySMRstiTP+F+OH//oTtdFtSXJuDbfMa8ZPpH8pBXCn/LmFvr2C5FcR36LMTynK+vYgnoGYgFuy7Pjfefigb/xd1KwgRkQJVKF1AIiKSRAlARKRAKQGIiBQoJQARkQKlBCAiUqCUAERECpQSgIhIgfr/PE+OyRejn58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FUNCIONES DE ACTIVACIÓN PARA REDES NEURONALES MULTICAPA\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit,softmax\n",
    "\n",
    "class function(object):\n",
    "    def __init__(self,funcion,derivative=None,rand_init=(0,1)):\n",
    "        self.F=funcion\n",
    "        self.D=derivative\n",
    "        self.Rand_init=rand_init\n",
    "\n",
    "lineal=function(funcion=lambda x:x,\n",
    "                derivative=lambda x:1,\n",
    "                rand_init=(-1,1))\n",
    "\n",
    "sigm=function(funcion=lambda x: expit(x),\n",
    "              derivative=lambda x: expit(x)*(1-expit(x)),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "tanh=function(funcion=lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)),\n",
    "              derivative=lambda x:1-((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))**2,\n",
    "              rand_init=(-1,1))\n",
    "\n",
    "tanh1=function(funcion=lambda x:np.tanh(x),\n",
    "               derivative=lambda x:1-np.tanh(x)**2,\n",
    "               rand_init=(-1,1))\n",
    "\n",
    "relu=function(funcion=lambda x: np.maximum(0, x),\n",
    "              derivative=lambda x: np.where(x<=0,0,1),\n",
    "              rand_init=(0,1))\n",
    "\n",
    "softmaxf=function(funcion=lambda x: softmax(x),\n",
    "                  derivative=lambda x:softmax(x)*(1-softmax(x)),\n",
    "                  rand_init=(0,1))\n",
    "\n",
    "\n",
    "# funciones de coste\n",
    "mse=function(funcion=lambda Yp, Yr: np.mean((Yp - Yr) ** 2) ,\n",
    "                 derivative=lambda Yp, Yr: (Yp - Yr))\n",
    "\n",
    "cross_entropy=function(funcion=lambda yscore,yreal:-np.sum(yreal*np.log(yscore))/yscore.shape[0],\n",
    "                       derivative=lambda yscore,yreal:yscore-yreal)\n",
    "\n",
    "Funciones={\"relu\":relu,\n",
    "           \"sigm\":sigm,\n",
    "           \"relu\":relu,\n",
    "           \"tanh\":tanh,\n",
    "           \"tanh1\":tanh1,\n",
    "           \"lineal\":lineal,\n",
    "           \"softmax\":softmaxf}\n",
    "\n",
    "Loss={\"mse\":mse,\n",
    "      \"cross_entropy\":cross_entropy}\n",
    "\n",
    "_x = np.linspace(-10, 10, 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(_x, softmaxf.F(_x),\"tab:blue\")\n",
    "plt.plot(_x, softmaxf.D(_x),\"tab:red\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
       "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
       "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
       "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
       "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
       "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
       "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
       "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
       "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
       "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
       "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
       "\n",
       "[395 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacer aquí la normalizacion de los datos\n",
    "import csv\n",
    "estudiantes = pd.read_csv('datasets/Maths.csv', encoding='utf-8' )\n",
    "estudiantes\n",
    "#X=[]\n",
    "#Y=[]\n",
    "#with open('datasets/iris.csv') as csvfile:\n",
    "#    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "#    for row in readCSV:\n",
    "#        row=row[0].split(\",\")\n",
    "#        X.append([float(row[0])/10,float(row[1])/10,float(row[2])/10,float(row[3])/10])\n",
    "#\n",
    "#        if row[4]=='\"Setosa\"':\n",
    "#            Y.append([1,0,0])\n",
    "#        if row[4]=='\"Versicolor\"':\n",
    "#            Y.append([0,1,0])\n",
    "#        if row[4]=='\"Virginica\"':\n",
    "#            Y.append([0,0,1])\n",
    "#\n",
    "#\n",
    "#Xtrain=np.array(X)\n",
    "#Ytrain=np.array(Y)\n",
    "#Xtrain=Xtrain[1:-1]\n",
    "#Ytrain=Ytrain[1:-1]\n",
    "#print(np.shape(Xtrain))\n",
    "#print(Xtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASE DE LA CAPA DE LA RED\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class neural_layer(object):\n",
    "    def __init__(self, n_conn, n_neur, activation=\"relu\"):\n",
    "        self.act = Funciones[activation]\n",
    "        self.activation=activation\n",
    "        self.random=self.act.Rand_init  \n",
    "        self.shape=(n_conn,n_neur)\n",
    "        self.Initialize()\n",
    "        \n",
    "    def show(self,Full=False):\n",
    "        print(f\"Pesos shape:{np.shape(self.W)} bias shape:{np.shape(self.b)} Activation:{self.activation}\")\n",
    "        print(f\"Activation:{self.activation}, Random:{self.random}\")\n",
    "        print(\"______________________\")\n",
    "        if Full:\n",
    "            print(f\"Pesos:\")\n",
    "            print(self.W)\n",
    "            print(\"#####\")\n",
    "            print(f\"Bias:\")\n",
    "            print(self.b)\n",
    "            \n",
    "    def Initialize(self):\n",
    "        #inicializa los pesos iniciales con aleatorios\n",
    "        self.b = np.random.uniform(*self.random,(1, self.shape[1]))      \n",
    "        self.W = np.random.uniform(*self.random,self.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "#CLASE RED NEURONAL MULTICAPA        \n",
    "class Neural_Net(object):\n",
    "    def __init__(self,Input,loss):\n",
    "        self.loss = Loss[loss]\n",
    "        self.Funcion_Loss=loss\n",
    "        self.Input=Input\n",
    "        self.NN=None;\n",
    "              \n",
    "    def Add_Layer(self,Num_neurons, function):\n",
    "        if self.NN is None:\n",
    "            self.NN=[]\n",
    "            self.NN.append(neural_layer(self.Input,Num_neurons,function))\n",
    "        else:\n",
    "            _,L_input=np.shape(self.NN[-1].W)\n",
    "            self.NN.append(neural_layer(L_input,Num_neurons,function))\n",
    "            \n",
    "    def Show_Model(self, Full=False):\n",
    "        print(f\"Input shape:{self.Input}, Loss: {self.Funcion_Loss}\")\n",
    "        for i,L in enumerate(self.NN):\n",
    "            print(F\"Layer_{i}:\")\n",
    "            L.show(Full)\n",
    "            \n",
    "            \n",
    "    # fucnción de predicción (fordware pass)    \n",
    "    def Predict(self,X):  \n",
    "      #sólo podemos pasar Numpy  \n",
    "      sx=np.shape(X)\n",
    "      X=X.reshape(1,sx[0])\n",
    "      if self.NN is None:\n",
    "          print(\"error in Predict Method ( not NEURAL network available)\")\n",
    "          return 0\n",
    "        \n",
    "      out = [(None, X)] #primer data necesario\n",
    "      # Forward pass\n",
    "      for l, layer in enumerate(self.NN):\n",
    "          z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "          a = self.NN[l].act.F(z)\n",
    "          out.append((z, a))\n",
    "      return out[-1][1]\n",
    "    \n",
    "    \n",
    "    # función retropropagación del error\n",
    "    def _backward_pass(self, X, Y,lr=0.01):\n",
    "      sx=np.shape(X)\n",
    "      sy=np.shape(Y)   \n",
    "      X=X.reshape(1,sx[0])\n",
    "      Y=Y.reshape(1,sy[0])\n",
    "\n",
    "      # Forward pass\n",
    "      out = [(None, X)] #primer data necesario\n",
    "      for l, layer in enumerate(self.NN):\n",
    "            z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "            a = self.NN[l].act.F(z)\n",
    "            out.append((z, a))\n",
    "\n",
    "      # Backward pass \n",
    "      deltas = []\n",
    "      for l in reversed(range(0, len(self.NN))):\n",
    "        z = out[l+1][0]\n",
    "        a = out[l+1][1]\n",
    "        if l == len(self.NN) - 1:\n",
    "            deltas.insert(0, self.loss.D(a, Y) * self.NN[l].act.D(a)) # La última capa\n",
    "        else:\n",
    "            deltas.insert(0, deltas[0] @ _W.T * self.NN[l-1].act.D(a))\n",
    "        _W = self.NN[l].W #los pesos en la capa superior\n",
    " \n",
    "        # Gradient descent. actualizamos pesos \n",
    "        self.NN[l].b = self.NN[l].b - (deltas[0]* lr)\n",
    "        self.NN[l].W = self.NN[l].W - (lr * (out[l][1].T @ deltas[0]))\n",
    "      return out[-1][1]\n",
    "\n",
    "    # función de entrenamiento de la red\n",
    "    def Train(self,X,Y,lr=0.01,epoch=10,batch_size=1):\n",
    "        H_loss = []\n",
    "        H_acc=[]\n",
    "        \n",
    "        # inicializamos las capas neuronales a valores ramdom del rango de la función\n",
    "        for Layer in self.NN:\n",
    "            Layer.Initialize()\n",
    "            \n",
    "        for i in range(epoch):\n",
    "            account=0\n",
    "            epoch_Loss=0\n",
    "            epoch_Acc=0\n",
    "            # Entrenemos a la red! con el dataset de validación\n",
    "            for j in range(len(X)):\n",
    "                pY = self._backward_pass(X[j,:], Y[j,:],lr)#fila, fila, learning rate\n",
    "                epoch_Loss+=self.loss.F(pY[0],Y[j,:])\n",
    "                if (Y[j,:]==np.round(pY)).all():#condicion de acertar\n",
    "                    epoch_Acc+=1\n",
    "            H_acc.append(epoch_Acc/len(Y)*100)    \n",
    "            H_loss.append(epoch_Loss/len(Y))#media del error\n",
    "            \n",
    "            #imprimimos por pantalla resultados\n",
    "            print(\"Epoch={}, Accurary={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "            clear_output(wait=True)\n",
    "        print(\"Epoch={}, Accuracy={} Loss={}\".format(i,round(H_acc[-1],3),round(H_loss[-1],7)))\n",
    "        return H_loss,H_acc\n",
    "\n",
    "    \n",
    "# VISUALIZACIÓN Y TEST\n",
    "def Show_Loss_Acc(H_loss,H_acc):\n",
    "    plt.plot(range(len(H_loss)), H_loss,\"tab:blue\")\n",
    "    plt.ylabel(\"loss function \")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(H_acc)), H_acc, \"tab:red\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "       \n",
    "def print_predict(neural_net,X,Y):\n",
    "    for i in range(len(X)):\n",
    "        sal_float=neural_net.Predict(X[i])\n",
    "        sal=np.round(sal_float)\n",
    "        \n",
    "        if (Y[i]==np.round(sal)).all():\n",
    "            print(\"Input:{}-- Real:{} predict: {} predict_float:{}\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "        else:\n",
    "            print(\"\\x1b[31m Input:{}-- Real:{} predict: {} predict_float:{}\\x1b[0m\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIMOS LOS MODELOs\n",
    "def Model1():\n",
    "    red=Neural_Net(Input=4,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(18,\"relu\")\n",
    "    red.Add_Layer(3,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model2():\n",
    "    red=Neural_Net(Input=4,loss=\"mse\")\n",
    "    red.Add_Layer(8,\"tanh\")\n",
    "    red.Add_Layer(3,\"sigm\")\n",
    "    return red\n",
    "\n",
    "def Model3(): \n",
    "    red=Neural_Net(Input=4,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(16,\"sigm\")\n",
    "    red.Add_Layer(24,\"tanh\")\n",
    "    red.Add_Layer(8,\"relu\")\n",
    "    red.Add_Layer(3,\"softmax\")\n",
    "    return red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:4, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(4, 18) bias shape:(1, 18) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.86745721 0.05998943 0.17086237 0.48126342 0.87638024 0.8207876\n",
      "  0.21959767 0.92537419 0.13053948 0.50721893 0.84977806 0.68595942\n",
      "  0.85299717 0.1958458  0.1762356  0.20131533 0.76504768 0.22942774]\n",
      " [0.71629967 0.57214855 0.61254776 0.31879545 0.38218942 0.36851811\n",
      "  0.94292864 0.65838132 0.92006335 0.38006288 0.61230622 0.24607676\n",
      "  0.56877802 0.45300441 0.24013256 0.54096239 0.66366328 0.74538729]\n",
      " [0.55299074 0.20196951 0.38182351 0.68145303 0.33430667 0.78431682\n",
      "  0.55688807 0.41479605 0.85136663 0.85467814 0.79045953 0.58092643\n",
      "  0.08381972 0.49497188 0.6648235  0.30540845 0.65150755 0.93728587]\n",
      " [0.1762181  0.67842585 0.37066939 0.01365761 0.2583893  0.64327766\n",
      "  0.46766748 0.47341304 0.26455259 0.74993593 0.31991285 0.67428804\n",
      "  0.92497113 0.07683379 0.72259801 0.01560119 0.26252084 0.39976486]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.82585347 0.62819882 0.32203586 0.81120709 0.53765906 0.11095215\n",
      "  0.80898343 0.12780569 0.41383184 0.04754482 0.13687133 0.66636161\n",
      "  0.33725498 0.28397664 0.50622727 0.9328935  0.90516324 0.39607346]]\n",
      "Layer_1:\n",
      "Pesos shape:(18, 3) bias shape:(1, 3) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.2517732  0.3932871  0.16708707]\n",
      " [0.80534382 0.39551553 0.72455816]\n",
      " [0.74196038 0.99619443 0.44679137]\n",
      " [0.16611235 0.55389648 0.12154088]\n",
      " [0.01593411 0.12690581 0.8153753 ]\n",
      " [0.29108776 0.61871267 0.1932661 ]\n",
      " [0.85929645 0.32736997 0.68637354]\n",
      " [0.6210372  0.00771984 0.87535216]\n",
      " [0.98479704 0.91630547 0.27197512]\n",
      " [0.47014609 0.0890679  0.22032656]\n",
      " [0.4844769  0.08802825 0.19641361]\n",
      " [0.62625004 0.47598039 0.40912437]\n",
      " [0.74654688 0.68666051 0.02200134]\n",
      " [0.52774474 0.23784805 0.8052699 ]\n",
      " [0.9862548  0.2605802  0.89993845]\n",
      " [0.14394419 0.4675604  0.33099398]\n",
      " [0.21902261 0.00281254 0.42323991]\n",
      " [0.56054394 0.22767692 0.96809457]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.14106093 0.50818193 0.7329766 ]]\n"
     ]
    }
   ],
   "source": [
    "cnn=Model1()\n",
    "#cnn.Show_Model()\n",
    "cnn.Show_Model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss,accuracy\u001b[38;5;241m=\u001b[39mcnn\u001b[38;5;241m.\u001b[39mTrain(\u001b[43mXtrain\u001b[49m,Ytrain,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m      2\u001b[0m Show_Loss_Acc(loss,accuracy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "loss,accuracy=cnn.Train(Xtrain,Ytrain,0.2,300)\n",
    "Show_Loss_Acc(loss,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:[0.49 0.3  0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.47 0.32 0.13 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.46 0.31 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.36 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.54 0.39 0.17 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.46 0.34 0.14 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.34 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.44 0.29 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.49 0.31 0.15 0.01]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.54 0.37 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.48 0.34 0.16 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.48 0.3  0.14 0.01]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.43 0.3  0.11 0.01]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[1. 0. 0.]]\n",
      "Input:[0.58 0.4  0.12 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.57 0.44 0.15 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.54 0.39 0.13 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.51 0.35 0.14 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.57 0.38 0.17 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.51 0.38 0.15 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.54 0.34 0.17 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.51 0.37 0.15 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.46 0.36 0.1  0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[1. 0. 0.]]\n",
      "Input:[0.51 0.33 0.17 0.05]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.97 0.03 0.  ]]\n",
      "Input:[0.48 0.34 0.19 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.5  0.3  0.16 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.5  0.34 0.16 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.52 0.35 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.52 0.34 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.47 0.32 0.16 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.48 0.31 0.16 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.54 0.34 0.15 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.52 0.41 0.15 0.01]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.55 0.42 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.49 0.31 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.32 0.12 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.55 0.35 0.13 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.49 0.36 0.14 0.01]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.44 0.3  0.13 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.51 0.34 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.35 0.13 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.45 0.23 0.13 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.44 0.32 0.13 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.35 0.16 0.06]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.98 0.02 0.  ]]\n",
      "Input:[0.51 0.38 0.19 0.04]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.97 0.03 0.  ]]\n",
      "Input:[0.48 0.3  0.14 0.03]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.51 0.38 0.16 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.46 0.32 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.53 0.37 0.15 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "Input:[0.5  0.33 0.14 0.02]-- Real:[1 0 0] predict: [[1. 0. 0.]] predict_float:[[0.99 0.01 0.  ]]\n",
      "\u001b[31m Input:[0.7  0.32 0.47 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.16 0.84]]\u001b[0m\n",
      "\u001b[31m Input:[0.64 0.32 0.45 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.16 0.84]]\u001b[0m\n",
      "\u001b[31m Input:[0.69 0.31 0.49 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.05 0.95]]\u001b[0m\n",
      "\u001b[31m Input:[0.55 0.23 0.4  0.13]-- Real:[0 1 0] predict: [[0. 0. 0.]] predict_float:[[0.02 0.48 0.5 ]]\u001b[0m\n",
      "\u001b[31m Input:[0.65 0.28 0.46 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.  0.1 0.9]]\u001b[0m\n",
      "\u001b[31m Input:[0.57 0.28 0.45 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.14 0.86]]\u001b[0m\n",
      "\u001b[31m Input:[0.63 0.33 0.47 0.16]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.05 0.95]]\u001b[0m\n",
      "Input:[0.49 0.24 0.33 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.28 0.7  0.02]]\n",
      "\u001b[31m Input:[0.66 0.29 0.46 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.  0.2 0.8]]\u001b[0m\n",
      "\u001b[31m Input:[0.52 0.27 0.39 0.14]-- Real:[0 1 0] predict: [[0. 0. 0.]] predict_float:[[0.03 0.48 0.48]]\u001b[0m\n",
      "Input:[0.5  0.2  0.35 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.16 0.78 0.06]]\n",
      "\u001b[31m Input:[0.59 0.3  0.42 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.29 0.7 ]]\u001b[0m\n",
      "Input:[0.6  0.22 0.4  0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.04 0.77 0.19]]\n",
      "\u001b[31m Input:[0.61 0.29 0.47 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.07 0.93]]\u001b[0m\n",
      "Input:[0.56 0.29 0.36 0.13]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.12 0.79 0.09]]\n",
      "\u001b[31m Input:[0.67 0.31 0.44 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.34 0.65]]\u001b[0m\n",
      "\u001b[31m Input:[0.56 0.3  0.45 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.08 0.92]]\u001b[0m\n",
      "Input:[0.58 0.27 0.41 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.04 0.7  0.26]]\n",
      "\u001b[31m Input:[0.62 0.22 0.45 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.09 0.91]]\u001b[0m\n",
      "Input:[0.56 0.25 0.39 0.11]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.06 0.74 0.21]]\n",
      "\u001b[31m Input:[0.59 0.32 0.48 0.18]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\u001b[0m\n",
      "Input:[0.61 0.28 0.4  0.13]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.03 0.66 0.3 ]]\n",
      "\u001b[31m Input:[0.63 0.25 0.49 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.02 0.98]]\u001b[0m\n",
      "\u001b[31m Input:[0.61 0.28 0.47 0.12]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.12 0.88]]\u001b[0m\n",
      "\u001b[31m Input:[0.64 0.29 0.43 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.44 0.55]]\u001b[0m\n",
      "\u001b[31m Input:[0.66 0.3  0.44 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.31 0.68]]\u001b[0m\n",
      "\u001b[31m Input:[0.68 0.28 0.48 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.08 0.92]]\u001b[0m\n",
      "\u001b[31m Input:[0.67 0.3  0.5  0.17]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\u001b[0m\n",
      "\u001b[31m Input:[0.6  0.29 0.45 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.  0.1 0.9]]\u001b[0m\n",
      "Input:[0.57 0.26 0.35 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.18 0.8  0.02]]\n",
      "Input:[0.55 0.24 0.38 0.11]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.07 0.77 0.16]]\n",
      "Input:[0.55 0.24 0.37 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.11 0.81 0.08]]\n",
      "Input:[0.58 0.27 0.39 0.12]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.05 0.73 0.21]]\n",
      "\u001b[31m Input:[0.6  0.27 0.51 0.16]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\u001b[0m\n",
      "\u001b[31m Input:[0.54 0.3  0.45 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.06 0.93]]\u001b[0m\n",
      "\u001b[31m Input:[0.6  0.34 0.45 0.16]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.09 0.9 ]]\u001b[0m\n",
      "\u001b[31m Input:[0.67 0.31 0.47 0.15]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.09 0.91]]\u001b[0m\n",
      "\u001b[31m Input:[0.63 0.23 0.44 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.25 0.75]]\u001b[0m\n",
      "\u001b[31m Input:[0.56 0.3  0.41 0.13]-- Real:[0 1 0] predict: [[0. 0. 0.]] predict_float:[[0.03 0.48 0.49]]\u001b[0m\n",
      "Input:[0.55 0.25 0.4  0.13]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.03 0.5  0.47]]\n",
      "\u001b[31m Input:[0.55 0.26 0.44 0.12]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.21 0.79]]\u001b[0m\n",
      "\u001b[31m Input:[0.61 0.3  0.46 0.14]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.   0.1  0.89]]\u001b[0m\n",
      "Input:[0.58 0.26 0.4  0.12]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.04 0.65 0.31]]\n",
      "Input:[0.5  0.23 0.33 0.1 ]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.26 0.72 0.02]]\n",
      "\u001b[31m Input:[0.56 0.27 0.42 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.34 0.65]]\u001b[0m\n",
      "\u001b[31m Input:[0.57 0.3  0.42 0.12]-- Real:[0 1 0] predict: [[0. 0. 0.]] predict_float:[[0.02 0.48 0.5 ]]\u001b[0m\n",
      "\u001b[31m Input:[0.57 0.29 0.42 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.02 0.39 0.6 ]]\u001b[0m\n",
      "\u001b[31m Input:[0.62 0.29 0.43 0.13]-- Real:[0 1 0] predict: [[0. 0. 1.]] predict_float:[[0.01 0.39 0.6 ]]\u001b[0m\n",
      "Input:[0.51 0.25 0.3  0.11]-- Real:[0 1 0] predict: [[0. 1. 0.]] predict_float:[[0.41 0.59 0.  ]]\n",
      "\u001b[31m Input:[0.57 0.28 0.41 0.13]-- Real:[0 1 0] predict: [[0. 0. 0.]] predict_float:[[0.02 0.48 0.5 ]]\u001b[0m\n",
      "Input:[0.63 0.33 0.6  0.25]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.58 0.27 0.51 0.19]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.71 0.3  0.59 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.63 0.29 0.56 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.65 0.3  0.58 0.22]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.76 0.3  0.66 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.49 0.25 0.45 0.17]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.02 0.98]]\n",
      "Input:[0.73 0.29 0.63 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.67 0.25 0.58 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.72 0.36 0.61 0.25]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.65 0.32 0.51 0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.64 0.27 0.53 0.19]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.68 0.3  0.55 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.57 0.25 0.5  0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.58 0.28 0.51 0.24]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.64 0.32 0.53 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.65 0.3  0.55 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.77 0.38 0.67 0.22]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.77 0.26 0.69 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.6  0.22 0.5  0.15]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.69 0.32 0.57 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.56 0.28 0.49 0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.77 0.28 0.67 0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.63 0.27 0.49 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.67 0.33 0.57 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.72 0.32 0.6  0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.62 0.28 0.48 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.61 0.3  0.49 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.64 0.28 0.56 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.72 0.3  0.58 0.16]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.74 0.28 0.61 0.19]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.79 0.38 0.64 0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.64 0.28 0.56 0.22]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.63 0.28 0.51 0.15]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.61 0.26 0.56 0.14]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.77 0.3  0.61 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.63 0.34 0.56 0.24]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.64 0.31 0.55 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.6  0.3  0.48 0.18]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0.   0.01 0.99]]\n",
      "Input:[0.69 0.31 0.54 0.21]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.67 0.31 0.56 0.24]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.69 0.31 0.51 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.58 0.27 0.51 0.19]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.68 0.32 0.59 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.67 0.33 0.57 0.25]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.67 0.3  0.52 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.63 0.25 0.5  0.19]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.65 0.3  0.52 0.2 ]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "Input:[0.62 0.34 0.54 0.23]-- Real:[0 0 1] predict: [[0. 0. 1.]] predict_float:[[0. 0. 1.]]\n",
      "::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_predict(cnn,Xtrain,Ytrain)\n",
    "print(\"::::::::::::::::::::::::::::\")\n",
    "\n",
    "\n",
    "np.round(cnn.Predict(np.array([0.51,0.35,0.14,0.02])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
